{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install torch==1.12.1\n","!pip install torchdata\n","!pip install -U torchtext"],"metadata":{"id":"gfM17qWslTY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzpQ8WO4HdMS"},"outputs":[],"source":["CBOW_N_WORDS = 4\n","SKIPGRAM_N_WORDS = 4\n","\n","MIN_WORD_FREQUENCY = 50\n","MAX_SEQUENCE_LENGTH = 256\n","\n","EMBED_DIMENSION = 300\n","EMBED_MAX_NORM = 1\n","\n","import torch\n","from functools import partial\n","from torch.utils.data import DataLoader\n","from torchtext.data import to_map_style_dataset\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import WikiText2, WikiText103\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","\n","def get_english_tokenizer():\n","    \"\"\"\n","    Documentation:\n","    https://pytorch.org/text/stable/_modules/torchtext/data/utils.html#get_tokenizer\n","    \"\"\"\n","    tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n","    return tokenizer\n","\n","\n","def get_data_iterator(ds_name, ds_type, data_dir):\n","    if ds_name == \"WikiText2\":\n","        data_iter = WikiText2(root=data_dir, split=(ds_type))\n","    elif ds_name == \"WikiText103\":\n","        data_iter = WikiText103(root=data_dir, split=(ds_type))\n","    else:\n","        raise ValueError(\"Choose dataset from: WikiText2, WikiText103\")\n","    data_iter = to_map_style_dataset(data_iter)\n","    return data_iter\n","\n","\n","def build_vocab(data_iter, tokenizer):\n","    \"\"\"Builds vocabulary from iterator\"\"\"\n","    \n","    vocab = build_vocab_from_iterator(\n","        map(tokenizer, data_iter),\n","        specials=[\"<unk>\"],\n","        min_freq=MIN_WORD_FREQUENCY,\n","    )\n","    vocab.set_default_index(vocab[\"<unk>\"])\n","    return vocab\n","\n","\n","def collate_cbow(batch, text_pipeline):\n","    \"\"\"\n","    Collate_fn for CBOW model to be used with Dataloader.\n","    `batch` is expected to be list of text paragrahs.\n","    \n","    Context is represented as N=CBOW_N_WORDS past words \n","    and N=CBOW_N_WORDS future words.\n","    \n","    Long paragraphs will be truncated to contain\n","    no more that MAX_SEQUENCE_LENGTH tokens.\n","    \n","    Each element in `batch_input` is N=CBOW_N_WORDS*2 context words.\n","    Each element in `batch_output` is a middle word.\n","    \"\"\"\n","    batch_input, batch_output = [], []\n","    for text in batch:\n","        text_tokens_ids = text_pipeline(text)\n","\n","        if len(text_tokens_ids) < CBOW_N_WORDS * 2 + 1:\n","            continue\n","\n","        if MAX_SEQUENCE_LENGTH:\n","            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n","\n","        for idx in range(len(text_tokens_ids) - CBOW_N_WORDS * 2):\n","            token_id_sequence = text_tokens_ids[idx : (idx + CBOW_N_WORDS * 2 + 1)]\n","            output = token_id_sequence.pop(CBOW_N_WORDS)\n","            input_ = token_id_sequence\n","            batch_input.append(input_)\n","            batch_output.append(output)\n","\n","    batch_input = torch.tensor(batch_input, dtype=torch.long)\n","    batch_output = torch.tensor(batch_output, dtype=torch.long)\n","    return batch_input, batch_output\n","\n","\n","def collate_skipgram(batch, text_pipeline):\n","    \"\"\"\n","    Collate_fn for Skip-Gram model to be used with Dataloader.\n","    `batch` is expected to be list of text paragrahs.\n","    \n","    Context is represented as N=SKIPGRAM_N_WORDS past words \n","    and N=SKIPGRAM_N_WORDS future words.\n","    \n","    Long paragraphs will be truncated to contain\n","    no more that MAX_SEQUENCE_LENGTH tokens.\n","    \n","    Each element in `batch_input` is a middle word.\n","    Each element in `batch_output` is a context word.\n","    \"\"\"\n","    batch_input, batch_output = [], []\n","    for text in batch:\n","        text_tokens_ids = text_pipeline(text)\n","\n","        if len(text_tokens_ids) < SKIPGRAM_N_WORDS * 2 + 1:\n","            continue\n","\n","        if MAX_SEQUENCE_LENGTH:\n","            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n","\n","        for idx in range(len(text_tokens_ids) - SKIPGRAM_N_WORDS * 2):\n","            token_id_sequence = text_tokens_ids[idx : (idx + SKIPGRAM_N_WORDS * 2 + 1)]\n","            input_ = token_id_sequence.pop(SKIPGRAM_N_WORDS)\n","            outputs = token_id_sequence\n","\n","            for output in outputs:\n","                batch_input.append(input_)\n","                batch_output.append(output)\n","\n","    batch_input = torch.tensor(batch_input, dtype=torch.long)\n","    batch_output = torch.tensor(batch_output, dtype=torch.long)\n","    return batch_input, batch_output\n","\n","\n","def get_dataloader_and_vocab(\n","    model_name, ds_name, ds_type, data_dir, batch_size, shuffle, vocab=None\n","):\n","\n","    data_iter = get_data_iterator(ds_name, ds_type, data_dir)\n","    tokenizer = get_english_tokenizer()\n","\n","    if not vocab:\n","        vocab = build_vocab(data_iter, tokenizer)\n","        \n","    text_pipeline = lambda x: vocab(tokenizer(x))\n","\n","    if model_name == \"cbow\":\n","        collate_fn = collate_cbow\n","    elif model_name == \"skipgram\":\n","        collate_fn = collate_skipgram\n","    else:\n","        raise ValueError(\"Choose model from: cbow, skipgram\")\n","\n","    dataloader = DataLoader(\n","        data_iter,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        collate_fn=partial(collate_fn, text_pipeline=text_pipeline),\n","    )\n","    return dataloader, vocab\n","\n","import os\n","import yaml\n","import torch\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","\n","\n","def get_model_class(model_name: str):\n","    if model_name == \"cbow\":\n","        return CBOW_Model\n","    elif model_name == \"skipgram\":\n","        return SkipGram_Model\n","    else:\n","        raise ValueError(\"Choose model_name from: cbow, skipgram\")\n","        return\n","\n","\n","def get_optimizer_class(name: str):\n","    if name == \"Adam\":\n","        return optim.Adam\n","    else:\n","        raise ValueError(\"Choose optimizer from: Adam\")\n","        return\n","    \n","\n","def get_lr_scheduler(optimizer, total_epochs: int, verbose: bool = True):\n","    \"\"\"\n","    Scheduler to linearly decrease learning rate, \n","    so thatlearning rate after the last epoch is 0.\n","    \"\"\"\n","    lr_lambda = lambda epoch: (total_epochs - epoch) / total_epochs\n","    lr_scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda, verbose=verbose)\n","    return lr_scheduler\n","\n","\n","def save_config(config: dict, model_dir: str):\n","    \"\"\"Save config file to `model_dir` directory\"\"\"\n","    config_path = os.path.join(model_dir, \"config.yaml\")\n","    with open(config_path, \"w\") as stream:\n","        yaml.dump(config, stream)\n","        \n","        \n","def save_vocab(vocab, model_dir: str):\n","    \"\"\"Save vocab file to `model_dir` directory\"\"\"\n","    vocab_path = os.path.join(model_dir, \"vocab.pt\")\n","    torch.save(vocab, vocab_path)\n","\n","import torch.nn as nn\n","\n","\n","class CBOW_Model(nn.Module):\n","    \"\"\"\n","    Implementation of CBOW model described in paper:\n","    https://arxiv.org/abs/1301.3781\n","    \"\"\"\n","    def __init__(self, vocab_size: int):\n","        super(CBOW_Model, self).__init__()\n","        self.embeddings = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=EMBED_DIMENSION,\n","            max_norm=EMBED_MAX_NORM,\n","        )\n","        self.linear = nn.Linear(\n","            in_features=EMBED_DIMENSION,\n","            out_features=vocab_size,\n","        )\n","\n","    def forward(self, inputs_):\n","        x = self.embeddings(inputs_)\n","        x = x.mean(axis=1)\n","        x = self.linear(x)\n","        return x\n","\n","\n","class SkipGram_Model(nn.Module):\n","    \"\"\"\n","    Implementation of Skip-Gram model described in paper:\n","    https://arxiv.org/abs/1301.3781\n","    \"\"\"\n","    def __init__(self, vocab_size: int):\n","        super(SkipGram_Model, self).__init__()\n","        self.embeddings = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=EMBED_DIMENSION,\n","            max_norm=EMBED_MAX_NORM,\n","        )\n","        self.linear = nn.Linear(\n","            in_features=EMBED_DIMENSION,\n","            out_features=vocab_size,\n","        )\n","\n","    def forward(self, inputs_):\n","        x = self.embeddings(inputs_)\n","        x = self.linear(x)\n","        return x\n","\n","import os\n","import numpy as np\n","import json\n","import torch\n","\n","\n","class Trainer:\n","    \"\"\"Main class for model training\"\"\"\n","    \n","    def __init__(\n","        self,\n","        model,\n","        epochs,\n","        train_dataloader,\n","        train_steps,\n","        val_dataloader,\n","        val_steps,\n","        checkpoint_frequency,\n","        criterion,\n","        optimizer,\n","        lr_scheduler,\n","        device,\n","        model_dir,\n","        model_name,\n","        vocab,\n","        gn_male_list,\n","        gn_female_list,\n","        gendered_dimensions\n","    ):  \n","        self.model = model\n","        self.epochs = epochs\n","        self.train_dataloader = train_dataloader\n","        self.train_steps = train_steps\n","        self.val_dataloader = val_dataloader\n","        self.val_steps = val_steps\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.checkpoint_frequency = checkpoint_frequency\n","        self.lr_scheduler = lr_scheduler\n","        self.device = device\n","        self.model_dir = model_dir\n","        self.model_name = model_name\n","        self.vocab = vocab\n","        self.gn_male_list = gn_male_list\n","        self.gn_female_list = gn_female_list\n","        self.gendered_dimensions = gendered_dimensions\n","\n","        gendered_indices = self.vocab(self.gn_male_list + self.gn_female_list)\n","        self.neutral_indices = [v for k, v in self.vocab.get_stoi().items() if v not in gendered_indices]\n","\n","        self.loss = {\"train\": [], \"val\": []}\n","        self.model.to(self.device)\n","\n","    def train(self):\n","        for epoch in range(self.epochs):\n","            self._train_epoch()\n","            self._validate_epoch()\n","            print(\n","                \"Epoch: {}/{}, Train Loss={:.5f}, Val Loss={:.5f}\".format(\n","                    epoch + 1,\n","                    self.epochs,\n","                    self.loss[\"train\"][-1],\n","                    self.loss[\"val\"][-1],\n","                )\n","            )\n","\n","            self.lr_scheduler.step()\n","\n","            if self.checkpoint_frequency:\n","                self._save_checkpoint(epoch)\n","\n","    def _train_epoch(self):\n","        self.model.train()\n","        running_loss = []\n","        with torch.no_grad():\n","            male_vectors = self.model.embeddings(torch.IntTensor(self.vocab(self.gn_male_list)))[:, self.gendered_dimensions:]\n","            female_vectors = self.model.embeddings(torch.IntTensor(self.vocab(self.gn_female_list)))[:, self.gendered_dimensions:]\n","            gender_direction = torch.mean(male_vectors - female_vectors, dim=0)\n","        \n","        for i, batch_data in enumerate(self.train_dataloader, 1):\n","            inputs = batch_data[0].to(self.device)\n","            labels = batch_data[1].to(self.device)\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(inputs)\n","            loss = self.criterion(outputs, labels, self.model.embeddings, self.vocab, gender_direction, self.neutral_indices)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            running_loss.append(loss.item())\n","\n","            if i == self.train_steps:\n","                break\n","\n","        epoch_loss = np.mean(running_loss)\n","        self.loss[\"train\"].append(epoch_loss)\n","\n","    def _validate_epoch(self):\n","        self.model.eval()\n","        running_loss = []\n","\n","        with torch.no_grad():\n","            for i, batch_data in enumerate(self.val_dataloader, 1):\n","                inputs = batch_data[0].to(self.device)\n","                labels = batch_data[1].to(self.device)\n","\n","                outputs = self.model(inputs)\n","                loss = self.criterion(outputs, labels)\n","\n","                running_loss.append(loss.item())\n","\n","                if i == self.val_steps:\n","                    break\n","\n","        epoch_loss = np.mean(running_loss)\n","        self.loss[\"val\"].append(epoch_loss)\n","\n","    def _save_checkpoint(self, epoch):\n","        \"\"\"Save model checkpoint to `self.model_dir` directory\"\"\"\n","        epoch_num = epoch + 1\n","        if epoch_num % self.checkpoint_frequency == 0:\n","            model_path = \"checkpoint_{}.pt\".format(str(epoch_num).zfill(3))\n","            model_path = os.path.join(self.model_dir, model_path)\n","            torch.save(self.model, model_path)\n","\n","    def save_model(self):\n","        \"\"\"Save final model to `self.model_dir` directory\"\"\"\n","        model_path = os.path.join(self.model_dir, \"model.pt\")\n","        torch.save(self.model, model_path)\n","\n","    def save_loss(self):\n","        \"\"\"Save train/val loss as json file to `self.model_dir` directory\"\"\"\n","        loss_path = os.path.join(self.model_dir, \"loss.json\")\n","        with open(loss_path, \"w\") as fp:\n","            json.dump(self.loss, fp)"]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","# Load wordlists https://github.com/uclanlp/gn_glove/tree/master/wordlist\n","gn_male_list = [\"he\", \"actor\"]\n","gn_female_list = [\"she\", \"actress\"]\n","\n","gendered_dimensions = 1\n","\n","# Loss Functions for Learning Gender-Neutral Word Embeddings https://arxiv.org/pdf/1809.01496.pdf\n","def JDL1(embeddings, vocab, gn_male_list, gn_female_list):\n","    male_vectors = embeddings(torch.IntTensor(vocab(gn_male_list)))[:, :gendered_dimensions]\n","    female_vectors = embeddings(torch.IntTensor(vocab(gn_female_list)))[:, :gendered_dimensions]\n","    male_sum = torch.sum(male_vectors, axis=0)\n","    female_sum = torch.sum(female_vectors, axis=0)\n","    return -torch.sum(torch.abs(male_sum - female_sum))\n","\n","def JDL2(embeddings, vocab, gn_male_list, gn_female_list):\n","    beta1 = 1\n","    beta2 = -1\n","    e = torch.ones(gendered_dimensions)\n","    male_vectors = embeddings(torch.IntTensor(vocab(gn_male_list)))[:, :gendered_dimensions]\n","    female_vectors = embeddings(torch.IntTensor(vocab(gn_female_list)))[:, :gendered_dimensions]\n","    return torch.sum((beta1 * e - male_vectors) ** 2) + torch.sum((beta2 * e - female_vectors) ** 2)\n","\n","def JE(embeddings, vocab, gn_male_list, gn_female_list, gender_direction, neutral_indices):\n","    neutral_vectors = embeddings(torch.IntTensor(neutral_indices))[:, gendered_dimensions:]\n","    return torch.sum(torch.matmul(neutral_vectors, gender_direction) ** 2)\n","\n","def GN_Glove_Loss(output, target, embeddings, vocab, gender_direction, neutral_indices):\n","    return F.cross_entropy(output, target) + JDL1(embeddings, vocab, gn_male_list, gn_female_list) + JDL2(embeddings, vocab, gn_male_list, gn_female_list) \\\n","        + JE(embeddings, vocab, gn_male_list, gn_female_list, gender_direction, neutral_indices)"],"metadata":{"id":"bp5URPIBpDT6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import yaml\n","import os\n","import torch\n","import torch.nn as nn\n","\n","model_dir = 'weights/cbow_WikiText2'\n","model_name = \"cbow\"\n","dataset = \"WikiText2\"\n","data_dir = 'data/'\n","train_batch_size = 96\n","val_batch_size = 96\n","shuffle = True\n","optimiz = 'Adam'\n","learning_rate = 0.025\n","epochs = 5\n","train_steps = None\n","val_steps = None\n","checkpoint_frequency = None\n","\n","def train():\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","    \n","    train_dataloader, vocab = get_dataloader_and_vocab(\n","        model_name=model_name,\n","        ds_name=dataset,\n","        ds_type=\"train\",\n","        data_dir=data_dir,\n","        batch_size=train_batch_size,\n","        shuffle=shuffle,\n","        vocab=None,\n","    )\n","\n","    val_dataloader, _ = get_dataloader_and_vocab(\n","        model_name=model_name,\n","        ds_name=dataset,\n","        ds_type=\"valid\",\n","        data_dir=data_dir,\n","        batch_size=val_batch_size,\n","        shuffle=shuffle,\n","        vocab=vocab,\n","    )\n","\n","    vocab_size = len(vocab.get_stoi())\n","    print(f\"Vocabulary size: {vocab_size}\")\n","\n","    model_class = get_model_class(model_name)\n","    model = model_class(vocab_size=vocab_size)\n","    criterion = GN_Glove_Loss\n","\n","    optimizer_class = get_optimizer_class(optimiz)\n","    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n","    lr_scheduler = get_lr_scheduler(optimizer, epochs, verbose=True)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","\n","    trainer = Trainer(\n","        model=model,\n","        epochs=epochs,\n","        train_dataloader=train_dataloader,\n","        train_steps=train_steps,\n","        val_dataloader=val_dataloader,\n","        val_steps=val_steps,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        checkpoint_frequency=checkpoint_frequency,\n","        lr_scheduler=lr_scheduler,\n","        device=device,\n","        model_dir=model_dir,\n","        model_name=model_name,\n","        vocab=vocab,\n","        gn_male_list=gn_male_list,\n","        gn_female_list=gn_female_list,\n","        gendered_dimensions=1\n","    )\n","\n","    trainer.train()\n","    print(\"Training finished.\")\n","\n","    trainer.save_model()\n","    trainer.save_loss()\n","    save_vocab(vocab, model_dir)\n","    #save_config(config, model_dir)\n","    print(\"Model artifacts saved to folder:\", model_dir)\n","    "],"metadata":{"id":"kTm4Og8gIBhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.autograd.set_detect_anomaly(False)\n","train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"s8PDfdODJl63","executionInfo":{"status":"error","timestamp":1669849059043,"user_tz":300,"elapsed":193749,"user":{"displayName":"Anh Tuấn Trần","userId":"02325967989134933351"}},"outputId":"7c2d4edb-7f55-4106-f4d4-0a39b3512063"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 4099\n","Adjusting learning rate of group 0 to 2.5000e-02.\n","cpu\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-63bf3de4a4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-71-7342666b4bb5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-35facd4df34c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             print(\n","\u001b[0;32m<ipython-input-69-35facd4df34c>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneutral_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import sys\n","\n","from sklearn.manifold import TSNE\n","import plotly.graph_objects as go\n","\n","folder = \"weights/cbow_WikiText2\"\n","#!ls \"weights/cbow_wikitext103_20/model.pt\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#model = CBOW_Model(vocab_size=300)\n","model = torch.load(f\"{folder}/model.pt\", map_location=device)\n","#model.load_state_dict(torch.load(f\"{folder}/model.pt\", map_location=device))\n","vocab = torch.load(f\"{folder}/vocab.pt\")"],"metadata":{"id":"sXI5Uc_yQUJN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings = list(model.parameters())[0]\n","embeddings = embeddings.cpu().detach().numpy()\n","print(embeddings.shape)\n","\n","norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n","norms = np.reshape(norms, (len(norms), 1))\n","embeddings_norm = embeddings / norms\n","embeddings_norm.shape\n","\n","embeddings_df = pd.DataFrame(embeddings)\n","\n","# t-SNE transform\n","tsne = TSNE(n_components=2)\n","embeddings_df_trans = tsne.fit_transform(embeddings_df)\n","embeddings_df_trans = pd.DataFrame(embeddings_df_trans)\n","\n","# get token order\n","embeddings_df_trans.index = vocab.get_itos()\n","print(embeddings_df_trans.index)\n","\n","# if token is a number\n","is_numeric = embeddings_df_trans.index.str.isnumeric()\n","\n","color = np.where(is_numeric, \"green\", \"black\")\n","fig = go.Figure()\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=embeddings_df_trans[0],\n","        y=embeddings_df_trans[1],\n","        mode=\"text\",\n","        text=embeddings_df_trans.index,\n","        textposition=\"middle center\",\n","        textfont=dict(color=color),\n","    )\n",")\n","fig.write_html(\"word2vec_visualization.html\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8pZ8vneR_0N","executionInfo":{"status":"ok","timestamp":1669488468877,"user_tz":300,"elapsed":40745,"user":{"displayName":"Siqi Hao","userId":"16003167311170492372"}},"outputId":"b1ae1822-8718-462a-b523-d7e6ad9ed5c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4099, 300)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Index(['<unk>', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a', '=',\n","       ...\n","       'seem', 'sheffield', 'signs', 'swiss', 'toured', 'underneath',\n","       'violent', 'wagner', 'walking', 'weapon'],\n","      dtype='object', length=4099)\n"]}]},{"cell_type":"code","source":["def get_top_similar(word: str, topN: int = 10):\n","    word_id = vocab[word]\n","    if word_id == 0:\n","        print(\"Out of vocabulary word\")\n","        return\n","\n","    word_vec = embeddings_norm[word_id]\n","    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n","    dists = np.matmul(embeddings_norm, word_vec).flatten()\n","    topN_ids = np.argsort(-dists)[1 : topN + 1]\n","\n","    topN_dict = {}\n","    for sim_word_id in topN_ids:\n","        sim_word = vocab.lookup_token(sim_word_id)\n","        topN_dict[sim_word] = dists[sim_word_id]\n","    return topN_dict\n","\n","dic = get_top_similar(\"germany\")\n","\n","for word, sim in dic.items():\n","    print(\"{}: {:.3f}\".format(word, sim))\n","\n","emb1 = embeddings[vocab[\"king\"]]\n","emb2 = embeddings[vocab[\"man\"]]\n","emb3 = embeddings[vocab[\"woman\"]]\n","\n","emb4 = emb1 - emb2 + emb3\n","emb4_norm = (emb4 ** 2).sum() ** (1 / 2)\n","emb4 = emb4 / emb4_norm\n","\n","emb4 = np.reshape(emb4, (len(emb4), 1))\n","dists = np.matmul(embeddings_norm, emb4).flatten()\n","\n","top5 = np.argsort(-dists)[:5]\n","\n","for word_id in top5:\n","    print(word_id)\n","    print(\"{}: {:.3f}\".format(vocab.lookup_token(word_id), dists[word_id]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m87roogwQdeH","executionInfo":{"status":"ok","timestamp":1669488480944,"user_tz":300,"elapsed":364,"user":{"displayName":"Siqi Hao","userId":"16003167311170492372"}},"outputId":"1ec22827-2c5c-4b3c-8b36-34309c5aad4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["italy: 0.713\n","france: 0.683\n","japan: 0.624\n","1945: 0.614\n","ireland: 0.595\n","scotland: 0.587\n","addition: 0.587\n","1972: 0.575\n","1961: 0.573\n","europe: 0.571\n","287\n","king: 0.835\n","807\n","henry: 0.597\n","1716\n","edward: 0.567\n","1139\n","daughter: 0.565\n","4016\n","philip: 0.564\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","\"\"\"\n","Tools for data operations\n","Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\n","Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, and Adam Kalai\n","2016\n","\"\"\"\n","\n","def load_professions():\n","    professions_file = os.path.join('data', 'professions.json')\n","    with open(professions_file, 'r') as f:\n","        professions = json.load(f)\n","    print('Loaded professions\\n' +\n","          'Format:\\n' +\n","          'word,\\n' +\n","          'definitional female -1.0 -> definitional male 1.0\\n' +\n","          'stereotypical female -1.0 -> stereotypical male 1.0')\n","    return professions\n","\n","professions = [[\"accountant\", 0.0, 0.4], [\"acquaintance\", 0.0, 0.0], [\"actor\", 0.8, 0.0], [\"actress\", -1.0, 0.0], [\"adjunct_professor\", 0.0, 0.5], [\"administrator\", 0.0, 0.2], [\"adventurer\", 0.0, 0.5], [\"advocate\", 0.0, -0.1], [\"aide\", 0.0, -0.2], [\"alderman\", 0.7, 0.2], [\"alter_ego\", 0.0, 0.0], [\"ambassador\", 0.0, 0.7], [\"analyst\", 0.0, 0.4], [\"anthropologist\", 0.0, 0.4], [\"archaeologist\", 0.0, 0.6], [\"archbishop\", 0.4, 0.5], [\"architect\", 0.1, 0.6], [\"artist\", 0.0, -0.2], [\"artiste\", -0.1, -0.2], [\"assassin\", 0.1, 0.8], [\"assistant_professor\", 0.1, 0.4], [\"associate_dean\", 0.0, 0.4], [\"associate_professor\", 0.0, 0.4], [\"astronaut\", 0.1, 0.8], [\"astronomer\", 0.1, 0.5], [\"athlete\", 0.0, 0.7], [\"athletic_director\", 0.1, 0.7], [\"attorney\", 0.0, 0.3], [\"author\", 0.0, 0.1], [\"baker\", 0.0, -0.1], [\"ballerina\", -0.5, -0.5], [\"ballplayer\", 0.2, 0.8], [\"banker\", 0.0, 0.6], [\"barber\", 0.5, 0.5], [\"baron\", 0.6, 0.3], [\"barrister\", 0.1, 0.4], [\"bartender\", 0.0, 0.3], [\"biologist\", 0.0, 0.1], [\"bishop\", 0.6, 0.4], [\"bodyguard\", 0.1, 0.9], [\"bookkeeper\", 0.0, -0.4], [\"boss\", 0.0, 0.7], [\"boxer\", 0.1, 0.9], [\"broadcaster\", -0.1, 0.4], [\"broker\", 0.1, 0.5], [\"bureaucrat\", 0.1, 0.5], [\"businessman\", 0.8, 0.2], [\"businesswoman\", -0.9, -0.1], [\"butcher\", 0.1, 0.9], [\"butler\", 0.5, 0.5], [\"cab_driver\", 0.1, 0.8], [\"cabbie\", 0.1, 0.6], [\"cameraman\", 0.8, 0.1], [\"campaigner\", 0.0, 0.2], [\"captain\", 0.1, 0.6], [\"cardiologist\", 0.1, 0.5], [\"caretaker\", 0.0, -0.9], [\"carpenter\", 0.1, 0.8], [\"cartoonist\", 0.0, 0.5], [\"cellist\", -0.1, 0.0], [\"chancellor\", 0.1, 0.6], [\"chaplain\", 0.1, 0.6], [\"character\", 0.0, 0.0], [\"chef\", 0.0, 0.5], [\"chemist\", 0.0, 0.2], [\"choreographer\", -0.2, -0.2], [\"cinematographer\", 0.0, 0.5], [\"citizen\", 0.0, 0.0], [\"civil_servant\", 0.0, 0.2], [\"cleric\", 0.3, 0.3], [\"clerk\", 0.0, -0.5], [\"coach\", 0.1, 0.8], [\"collector\", 0.0, 0.4], [\"colonel\", 0.1, 0.8], [\"columnist\", 0.0, 0.2], [\"comedian\", 0.0, 0.3], [\"comic\", 0.1, 0.1], [\"commander\", 0.1, 0.8], [\"commentator\", 0.0, 0.4], [\"commissioner\", 0.0, 0.8], [\"composer\", 0.1, 0.4], [\"conductor\", 0.1, 0.6], [\"confesses\", 0.0, 0.0], [\"congressman\", 0.7, 0.3], [\"constable\", 0.2, 0.6], [\"consultant\", 0.0, 0.1], [\"cop\", 0.2, 0.6], [\"correspondent\", 0.0, 0.0], [\"councilman\", 0.8, 0.1], [\"councilor\", -0.1, -0.1], [\"counselor\", 0.0, -0.1], [\"critic\", 0.1, 0.4], [\"crooner\", 0.2, 0.2], [\"crusader\", 0.1, 0.7], [\"curator\", -0.1, 0.2], [\"custodian\", 0.1, 0.9], [\"dad\", 1.0, 0.0], [\"dancer\", -0.1, -0.9], [\"dean\", 0.2, 0.7], [\"dentist\", 0.0, 0.7], [\"deputy\", 0.1, 0.7], [\"dermatologist\", 0.0, -0.3], [\"detective\", 0.1, 0.5], [\"diplomat\", 0.0, 0.5], [\"director\", 0.1, 0.6], [\"disc_jockey\", 0.2, 0.6], [\"doctor\", 0.0, 0.7], [\"doctoral_student\", 0.0, 0.3], [\"drug_addict\", 0.0, 0.0], [\"drummer\", 0.0, 0.9], [\"economics_professor\", 0.1, 0.6], [\"economist\", 0.1, 0.5], [\"editor\", 0.1, 0.4], [\"educator\", 0.0, -0.5], [\"electrician\", 0.1, 0.8], [\"employee\", 0.0, 0.0], [\"entertainer\", 0.0, 0.0], [\"entrepreneur\", 0.0, 0.5], [\"environmentalist\", 0.0, -0.4], [\"envoy\", 0.1, 0.2], [\"epidemiologist\", 0.0, 0.0], [\"evangelist\", 0.1, 0.4], [\"farmer\", 0.1, 0.8], [\"fashion_designer\", -0.2, -0.4], [\"fighter_pilot\", 0.2, 0.7], [\"filmmaker\", 0.1, 0.3], [\"financier\", 0.1, 0.5], [\"firebrand\", 0.0, 0.1], [\"firefighter\", 0.1, 0.7], [\"fireman\", 0.8, 0.2], [\"fisherman\", 0.9, 0.1], [\"footballer\", 0.4, 0.5], [\"foreman\", 0.5, 0.4], [\"freelance_writer\", 0.0, 0.0], [\"gangster\", 0.2, 0.7], [\"gardener\", -0.1, 0.0], [\"geologist\", 0.0, 0.4], [\"goalkeeper\", 0.1, 0.5], [\"graphic_designer\", 0.0, 0.2], [\"guidance_counselor\", 0.0, 0.0], [\"guitarist\", 0.1, 0.5], [\"hairdresser\", -0.2, -0.8], [\"handyman\", 0.8, 0.2], [\"headmaster\", 0.4, 0.2], [\"historian\", 0.0, 0.5], [\"hitman\", 0.8, 0.2], [\"homemaker\", -0.1, -0.9], [\"hooker\", -0.2, -0.8], [\"housekeeper\", -0.2, -0.8], [\"housewife\", -1.0, 0.0], [\"illustrator\", 0.0, 0.2], [\"industrialist\", 0.1, 0.7], [\"infielder\", 0.1, 0.5], [\"inspector\", 0.1, 0.5], [\"instructor\", 0.0, -0.3], [\"interior_designer\", -0.2, -0.6], [\"inventor\", 0.1, 0.5], [\"investigator\", 0.1, 0.5], [\"investment_banker\", 0.1, 0.7], [\"janitor\", 0.1, 0.9], [\"jeweler\", 0.1, 0.3], [\"journalist\", -0.1, 0.3], [\"judge\", 0.0, 0.7], [\"jurist\", 0.0, 0.0], [\"laborer\", 0.1, 0.9], [\"landlord\", 0.1, 0.4], [\"lawmaker\", 0.0, 0.7], [\"lawyer\", 0.1, 0.5], [\"lecturer\", 0.0, 0.2], [\"legislator\", 0.1, 0.7], [\"librarian\", -0.1, -0.9], [\"lieutenant\", 0.1, 0.7], [\"lifeguard\", 0.0, 0.6], [\"lyricist\", 0.0, -0.2], [\"maestro\", 0.1, 0.5], [\"magician\", 0.1, 0.7], [\"magistrate\", 0.0, 0.8], [\"maid\", -0.4, -0.6], [\"major_leaguer\", 0.2, 0.7], [\"manager\", 0.0, 0.6], [\"marksman\", 0.6, 0.4], [\"marshal\", 0.1, 0.7], [\"mathematician\", 0.0, 0.8], [\"mechanic\", 0.3, 0.6], [\"mediator\", 0.0, -0.2], [\"medic\", 0.1, 0.4], [\"midfielder\", 0.3, 0.5], [\"minister\", 0.1, 0.8], [\"missionary\", 0.0, 0.3], [\"mobster\", 0.1, 0.9], [\"monk\", 0.8, 0.1], [\"musician\", 0.0, 0.0], [\"nanny\", -0.3, -0.7], [\"narrator\", 0.0, 0.2], [\"naturalist\", 0.0, -0.2], [\"negotiator\", 0.0, 0.3], [\"neurologist\", 0.0, 0.6], [\"neurosurgeon\", 0.0, 0.7], [\"novelist\", 0.0, 0.0], [\"nun\", -0.8, -0.1], [\"nurse\", -0.1, -0.9], [\"observer\", 0.0, -0.1], [\"officer\", 0.1, 0.8], [\"organist\", -0.2, -0.3], [\"painter\", 0.0, 0.2], [\"paralegal\", -0.1, -0.4], [\"parishioner\", 0.0, 0.1], [\"parliamentarian\", 0.0, 0.6], [\"pastor\", 0.3, 0.7], [\"pathologist\", 0.0, 0.3], [\"patrolman\", 1.0, 0.0], [\"pediatrician\", 0.0, -0.2], [\"performer\", 0.0, -0.2], [\"pharmacist\", 0.0, 0.3], [\"philanthropist\", 0.0, 0.3], [\"philosopher\", 0.0, 0.8], [\"photographer\", 0.0, -0.1], [\"photojournalist\", 0.0, 0.1], [\"physician\", 0.0, 0.6], [\"physicist\", 0.1, 0.7], [\"pianist\", 0.0, -0.1], [\"planner\", 0.0, -0.3], [\"plastic_surgeon\", 0.2, 0.4], [\"playwright\", 0.0, 0.5], [\"plumber\", 0.1, 0.8], [\"poet\", 0.0, -0.1], [\"policeman\", 0.8, 0.2], [\"politician\", 0.0, 0.5], [\"pollster\", 0.0, 0.3], [\"preacher\", 0.2, 0.7], [\"president\", 0.1, 0.9], [\"priest\", 0.7, 0.3], [\"principal\", 0.0, 0.3], [\"prisoner\", 0.1, 0.6], [\"professor\", 0.1, 0.4], [\"professor_emeritus\", 0.0, 0.5], [\"programmer\", 0.2, 0.6], [\"promoter\", 0.0, 0.3], [\"proprietor\", 0.1, 0.4], [\"prosecutor\", -0.1, 0.3], [\"protagonist\", 0.0, 0.1], [\"protege\", 0.0, 0.2], [\"protester\", -0.1, 0.0], [\"provost\", 0.0, 0.4], [\"psychiatrist\", 0.0, -0.2], [\"psychologist\", 0.0, 0.0], [\"publicist\", -0.1, -0.2], [\"pundit\", 0.0, 0.2], [\"rabbi\", 0.2, 0.6], [\"radiologist\", 0.0, -0.3], [\"ranger\", 0.2, 0.7], [\"realtor\", -0.2, -0.2], [\"receptionist\", -0.3, -0.7], [\"registered_nurse\", -0.1, -0.9], [\"researcher\", 0.0, 0.1], [\"restaurateur\", 0.0, 0.2], [\"sailor\", 0.1, 0.8], [\"saint\", 0.2, 0.3], [\"salesman\", 0.8, 0.2], [\"saxophonist\", 0.1, 0.5], [\"scholar\", 0.0, 0.6], [\"scientist\", 0.0, 0.5], [\"screenwriter\", 0.1, 0.4], [\"sculptor\", 0.0, 0.5], [\"secretary\", -0.2, -0.8], [\"senator\", 0.1, 0.7], [\"sergeant\", 0.1, 0.7], [\"servant\", 0.0, 0.1], [\"serviceman\", 0.7, 0.3], [\"sheriff_deputy\", 0.1, 0.8], [\"shopkeeper\", 0.0, 0.5], [\"singer\", 0.0, -0.2], [\"singer_songwriter\", 0.0, -0.3], [\"skipper\", 0.1, 0.7], [\"socialite\", -0.4, -0.3], [\"sociologist\", 0.0, -0.2], [\"soft_spoken\", -0.1, -0.9], [\"soldier\", 0.3, 0.6], [\"solicitor\", 0.1, 0.3], [\"solicitor_general\", 0.0, 0.5], [\"soloist\", -0.1, -0.3], [\"sportsman\", 0.9, 0.1], [\"sportswriter\", 0.1, 0.9], [\"statesman\", 0.6, 0.4], [\"steward\", 0.4, -0.1], [\"stockbroker\", 0.1, 0.5], [\"strategist\", 0.0, 0.3], [\"student\", 0.0, 0.0], [\"stylist\", -0.2, -0.7], [\"substitute\", -0.1, -0.1], [\"superintendent\", 0.0, 0.9], [\"surgeon\", 0.1, 0.7], [\"surveyor\", 0.0, 0.5], [\"swimmer\", 0.0, 0.0], [\"taxi_driver\", 0.1, 0.9], [\"teacher\", 0.0, -0.8], [\"technician\", 0.1, 0.6], [\"teenager\", 0.0, -0.1], [\"therapist\", -0.1, -0.4], [\"trader\", 0.1, 0.6], [\"treasurer\", 0.0, -0.3], [\"trooper\", 0.2, 0.5], [\"trucker\", 0.2, 0.7], [\"trumpeter\", 0.0, 0.2], [\"tutor\", 0.0, -0.3], [\"tycoon\", 0.1, 0.7], [\"undersecretary\", 0.0, -0.3], [\"understudy\", 0.0, 0.0], [\"valedictorian\", 0.0, 0.0], [\"vice_chancellor\", 0.0, 0.6], [\"violinist\", -0.1, -0.3], [\"vocalist\", 0.0, -0.3], [\"waiter\", 1.0, 0.0], [\"waitress\", -0.9, -0.1], [\"warden\", 0.1, 0.9], [\"warrior\", 0.1, 0.9], [\"welder\", 0.3, 0.6], [\"worker\", 0.0, 0.3], [\"wrestler\", 0.2, 0.6], [\"writer\", 0.0, 0.0]]\n","print(len(professions))\n","\n","profession_words = []\n","for i in range(len(professions)):\n","  if professions[i][0] in vocab:\n","    profession_words.append(professions[i][0])\n","print(profession_words)\n","print(len(profession_words))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdjBWeTxzgR4","executionInfo":{"status":"ok","timestamp":1669488486789,"user_tz":300,"elapsed":313,"user":{"displayName":"Siqi Hao","userId":"16003167311170492372"}},"outputId":"49e72423-aa55-45a9-8760-2da001a1f997"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["320\n","['actor', 'actress', 'ambassador', 'archaeologist', 'archbishop', 'artist', 'attorney', 'author', 'baker', 'bishop', 'captain', 'character', 'coach', 'colonel', 'comic', 'commander', 'composer', 'critic', 'dean', 'director', 'editor', 'historian', 'journalist', 'judge', 'lieutenant', 'manager', 'minister', 'musician', 'nurse', 'officer', 'poet', 'president', 'priest', 'principal', 'professor', 'protagonist', 'saint', 'scholar', 'secretary', 'singer', 'student', 'substitute', 'teacher', 'warrior', 'writer']\n","45\n"]}]},{"cell_type":"code","source":["import re\n","import sys\n","import numpy as np\n","import scipy.sparse\n","from sklearn.decomposition import PCA\n","\n","class WordEmbedding:\n","    def __init__(self):\n","        self.thresh = None\n","        self.max_words = None\n","        #self.vecs = embeddings\n","        #print(self.vecs.shape)\n","        #self.words = vocab\n","        self.words =[vocab.lookup_token(i) for i in range(len(vocab))]\n","        print(self.words)\n","        print(len(self.words))\n","        self.vecs = [embeddings[vocab[w]] for w in self.words]\n","        self.vecs = np.array(self.vecs, dtype='float32')\n","        print(self.vecs.shape)\n","        self.reindex()\n","        norms = np.linalg.norm(self.vecs, axis=1)\n","        if max(norms)-min(norms) > 0.0001:\n","            self.normalize()\n","\n","    def reindex(self):\n","        self.index = {w: i for i, w in enumerate(self.words)}\n","        self.n, self.d = self.vecs.shape\n","        assert self.n == len(self.words) == len(self.index)\n","        self._neighbors = None\n","        print(self.n, \"words of dimension\", self.d, \":\", \", \".join(self.words[:4] + [\"...\"] + self.words[-4:]))\n","\n","\n","    def v(self, word):\n","        return self.vecs[self.index[word]]\n","\n","    def diff(self, word1, word2):\n","        v = self.vecs[self.index[word1]] - self.vecs[self.index[word2]]\n","        return v/np.linalg.norm(v)\n","\n","    def normalize(self):\n","        self.vecs /= np.linalg.norm(self.vecs, axis=1)[:, np.newaxis]\n","\n","    def shrink(self, numwords):\n","        self.desc += \", shrink \" + str(numwords)\n","        self.filter_words(lambda w: self.index[w]<numwords)\n","\n","    def filter_words(self, test):\n","        \"\"\"\n","        Keep some words based on test, e.g. lambda x: x.lower()==x\n","        \"\"\"\n","        self.desc += \", filter\"\n","        kept_indices, words = zip(*[[i, w] for i, w in enumerate(self.words) if test(w)])\n","        self.words = list(words)\n","        self.vecs = self.vecs[kept_indices, :]\n","        self.reindex()\n","\n","    def save(self, filename):\n","        with open(filename, \"w\") as f:\n","            f.write(\"\\n\".join([w+\" \" + \" \".join([str(x) for x in v]) for w, v in zip(self.words, self.vecs)]))\n","        print(\"Wrote\", self.n, \"words to\", filename)\n","\n","    def save_w2v(self, filename, binary=True):\n","        with open(filename, 'wb') as fout:\n","            fout.write(to_utf8(\"%s %s\\n\" % self.vecs.shape))\n","            # store in sorted order: most frequent words at the top\n","            for i, word in enumerate(self.words):\n","                row = self.vecs[i]\n","                if binary:\n","                    fout.write(to_utf8(word) + b\" \" + row.tostring())\n","                else:\n","                    fout.write(to_utf8(\"%s %s\\n\" % (word, ' '.join(\"%f\" % val for val in row))))\n","\n","    def remove_directions(self, directions): #directions better be orthogonal\n","        self.desc += \", removed\"\n","        for direction in directions:\n","            self.desc += \" \"\n","            if type(direction) is np.ndarray:\n","                v = direction / np.linalg.norm(direction)\n","                self.desc += \"vector \"\n","            else:\n","                w1, w2 = direction\n","                v = self.diff(w1, w2)\n","                self.desc += w1 + \"-\" + w2\n","            self.vecs = self.vecs - self.vecs.dot(v)[:, np.newaxis].dot(v[np.newaxis, :])\n","        self.normalize()\n","\n","    def compute_neighbors_if_necessary(self, thresh, max_words):\n","        thresh = float(thresh) # dang python 2.7!\n","        if self._neighbors is not None and self.thresh == thresh and self.max_words == max_words:\n","            return\n","        print(\"Computing neighbors\")\n","        self.thresh = thresh\n","        self.max_words = max_words\n","        vecs = self.vecs[:max_words]\n","        dots = vecs.dot(vecs.T)\n","        dots = scipy.sparse.csr_matrix(dots * (dots >= 1-thresh/2))\n","        from collections import Counter\n","        rows, cols = dots.nonzero()\n","        nums = list(Counter(rows).values())\n","        print(\"Mean:\", np.mean(nums)-1)\n","        print(\"Median:\", np.median(nums)-1)\n","        rows, cols, vecs = zip(*[(i, j, vecs[i]-vecs[j]) for i, j, x in zip(rows, cols, dots.data) if i<j])\n","        self._neighbors = rows, cols, np.array([v/np.linalg.norm(v) for v in vecs])\n","\n","    def neighbors(self, word, thresh=1):\n","        dots = self.vecs.dot(self.v(word))\n","        return [self.words[i] for i, dot in enumerate(dots) if dot >= 1-thresh/2]\n","\n","    def more_words_like_these(self, words, topn=50, max_freq=100000):\n","        v = sum(self.v(w) for w in words)\n","        dots = self.vecs[:max_freq].dot(v)\n","        thresh = sorted(dots)[-topn]\n","        words = [w for w, dot in zip(self.words, dots) if dot>=thresh]\n","        return sorted(words, key=lambda w: self.v(w).dot(v))[-topn:][::-1]\n","\n","    def best_analogies_dist_thresh(self, v, thresh=1, topn=500, max_words=50000):\n","        \"\"\"Metric is cos(a-c, b-d) if |b-d|^2 < thresh, otherwise 0\n","        \"\"\"\n","        vecs, vocab = self.vecs[:max_words], self.words[:max_words]\n","        self.compute_neighbors_if_necessary(thresh, max_words)\n","        rows, cols, vecs = self._neighbors\n","        scores = vecs.dot(v/np.linalg.norm(v))\n","        pi = np.argsort(-abs(scores))\n","\n","        ans = []\n","        usedL = set()\n","        usedR = set()\n","        for i in pi:\n","            if abs(scores[i])<0.001:\n","                break\n","            row = rows[i] if scores[i] > 0 else cols[i]\n","            col = cols[i] if scores[i] > 0 else rows[i]\n","            if row in usedL or col in usedR:\n","                continue\n","            usedL.add(row)\n","            usedR.add(col)\n","            ans.append((vocab[row], vocab[col], abs(scores[i])))\n","            if len(ans)==topn:\n","                break\n","\n","        return ans\n","\n","def viz(analogies):\n","    print(\"\\n\".join(str(i).rjust(4)+a[0].rjust(29) + \" | \" + a[1].ljust(29) + (str(a[2]))[:4] for i, a in enumerate(analogies)))\n","\n","\n","def text_plot_words(xs, ys, words, width = 90, height = 40, filename=None):\n","    PADDING = 10 # num chars on left and right in case words spill over\n","    res = [[' ' for i in range(width)] for j in range(height)]\n","    def rescale(nums):\n","        a = min(nums)\n","        b = max(nums)\n","        return [(x-a)/(b-a) for x in nums]\n","    print(\"x:\", (min(xs), max(xs)), \"y:\",(min(ys),max(ys)))\n","    xs = rescale(xs)\n","    ys = rescale(ys)\n","    for (x, y, word) in zip(xs, ys, words):\n","        i = int(x*(width - 1 - PADDING))\n","        j = int(y*(height-1))\n","        row = res[j]\n","        z = list(row[i2] != ' ' for i2 in range(max(i-1, 0), min(width, i + len(word) + 1)))\n","        if any(z):\n","            continue\n","        for k in range(len(word)):\n","            if i+k>=width:\n","                break\n","            row[i+k] = word[k]\n","    string = \"\\n\".join(\"\".join(r) for r in res)\n","#     return string\n","    if filename:\n","        with open(filename, \"w\", encoding=\"utf8\") as f:\n","            f.write(string)\n","        print(\"Wrote to\", filename)\n","    else:\n","        print(string)\n","\n","\n","def doPCA(pairs, embedding, num_components = 10):\n","    matrix = []\n","    for a, b in pairs:\n","        center = (embedding.v(a) + embedding.v(b))/2\n","        matrix.append(embedding.v(a) - center)\n","        matrix.append(embedding.v(b) - center)\n","    matrix = np.array(matrix)\n","    pca = PCA(n_components = num_components)\n","    pca.fit(matrix)\n","    # bar(range(num_components), pca.explained_variance_ratio_)\n","    return pca\n","\n","\n","def drop(u, v):\n","    return u - v * u.dot(v) / v.dot(v)"],"metadata":{"id":"DFaea3r4qpDC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["we = WordEmbedding()\n","v_gender = we.diff('she', 'he')\n","#print(v_gender)\n","a_gender = we.best_analogies_dist_thresh(v_gender)\n","for (a,b,c) in a_gender:\n","    print(a+\"-\"+b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TKDph1srnHJ","executionInfo":{"status":"ok","timestamp":1669488493951,"user_tz":300,"elapsed":1042,"user":{"displayName":"Siqi Hao","userId":"16003167311170492372"}},"outputId":"f76bdce0-e8b9-486f-abb6-5a549fff10ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<unk>', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a', '=', 'was', \"'\", '@-@', 'on', 'as', 's', 'that', 'for', 'with', 'by', ')', '(', '@', 'is', 'it', 'from', 'at', 'his', 'he', 'were', 'an', 'had', 'which', 'be', 'are', 'this', 'their', 'first', 'but', 'not', '–', 'one', 'they', 'its', 'also', 'after', 'her', 'or', 'two', 'have', 'has', 'been', 'who', 'she', 'new', 'other', 'during', 'when', 'time', 'all', 'into', 'more', 'would', '1', 'i', 'over', 'while', 'game', 'only', 'most', '2', 'three', 'later', 'about', 'up', 'may', 'between', 'him', 'song', 'there', 'some', 'than', 'out', 'no', 'season', 'year', 'made', 'city', '3', 'such', 'before', 'where', 'used', 'series', 'them', 'second', 'world', 'being', 'years', 'both', '000', 'many', 'these', 'film', 'however', 'album', 'south', 'war', 'through', '5', 'north', 'then', 'can', 'part', 'early', 'several', '4', 'number', 'state', 'including', 'against', 'well', '/', 'known', 'became', '—', 'm', 'four', 'united', 'under', 'although', 'century', 'day', 'following', 'music', 'began', 'because', 'so', 'work', 'like', 'end', 'called', 'episode', 'until', 'found', 'said', 'area', 'could', 'states', 'american', 'people', '6', 'since', 'british', 'each', 'released', 'same', 'team', 'church', '10', 'around', 'long', 'did', 'along', 'million', 'five', 'life', 'national', '0', 'back', 'john', 'high', 'company', 't', 'another', 'best', 'use', '%', 'you', 'if', 'final', 'september', 'august', 'river', 'large', 'what', 'west', '8', 'km', 'off', 'down', '7', 'due', 'games', 'june', 'line', 'history', 'will', 'name', 'now', 'any', 'storm', 'home', 'received', '9', 'described', 'government', 'six', 'species', 'within', 'much', 'group', 'family', 'october', 'played', '$', 'east', 'league', 'general', 'set', 'took', '[', ']', 'major', 'road', 'july', 'wrote', 'late', 'single', 'won', 'system', 'play', 'video', 'times', 'us', 'according', 'record', 'third', 'based', 'april', 'man', 'included', 'just', 'march', 'book', 'those', 'january', 'show', 'named', 'even', 'very', 'england', 'main', 'white', 'left', 'york', 'men', 'school', 'small', 'though', 'division', 'club', 'way', 'old', 'original', 'near', 'last', '12', 'november', 'water', 'death', 'place', '20', '15', 'tropical', 'december', 'built', 'own', 'character', 'we', 'songs', 'top', 'de', 'form', '30', 'player', 'do', 'king', 'black', 'public', 'german', 'island', 'next', '2009', 'make', '2008', 'still', '2010', 'u', 'role', 'led', 'again', 'moved', 'career', 'ii', 'university', 'without', 'love', 'often', 'among', 'recorded', 'further', 'hurricane', 'military', 'period', 'star', 'local', 'considered', 'army', 'production', 'release', 'side', '2007', 'great', 'house', 'came', 'published', 'written', '100', 'continued', 'power', 'town', 'english', 'story', 'days', 'forces', 'run', 'held', 'route', 'french', 'support', '14', '16', '11', 'force', 'half', 'few', 'take', 'international', 'having', '25', 'county', 'land', 'throughout', '2011', 'point', '18', 'become', '2006', 'children', 'order', 'light', 'version', 'title', 'former', 'lost', 'track', 'different', '&', 'development', 'field', 'ship', 'similar', 'despite', 'live', 'common', 'members', 'park', 'c', 'february', '13', 'gave', 'produced', 'short', 'southern', '!', 'dylan', 'little', 'site', '2012', 'once', 'television', 'writing', 'given', 'central', 'control', 'total', 'band', 'country', 'service', 'northern', 're', 'include', 'young', 'fire', 'position', 'battalion', 'making', 'never', 'away', 'seven', 'tour', 'age', 'air', 'lead', '2013', 'how', 'open', 'reported', 'seen', 'battle', 'highway', 'eastern', 'good', 'western', 'stated', 'attack', 'red', 'god', 'h', 'match', 'across', 'st', 'body', 'instead', 'returned', 'ships', 'established', 'using', 'ft', 'population', 'america', 'construction', 'modern', 'week', 'noted', 'less', 'my', 'royal', 'head', 'reached', 'building', 'developed', 'eight', 'rock', 'ireland', 'players', 'brigade', 'b', 'president', 'result', 'thought', 'performance', 'right', 'london', 'miles', 'himself', 'father', 'per', 'important', 'style', 'performed', 'felt', 'australia', 'various', '17', 'full', 'areas', 'feet', 'previous', 'events', 'win', 'low', 'died', 'kingdom', 'guitar', 'football', 'others', 'art', 'mm', 'originally', 'project', 'too', 'went', 'human', '23', 'level', 'upon', 'range', 'works', 'formed', 'started', 'characters', 'james', 'political', 'women', 'should', 'cup', 'port', '50', 'caused', '21', '28', 'eventually', 'located', '19', '24', 'stars', 'critics', 'ground', 'sent', 'able', 'created', '2004', 'me', '2005', 'class', 'd', 'chart', 'night', 'born', 'region', 'street', 'center', 'court', 'design', 'together', 'director', 'popular', 'present', 'strong', 'award', 'every', '’', 'return', 'son', 'hero', 'remained', 'see', 'completed', 'guns', 'novel', 'scored', 'announced', 'australian', 'grand', '22', 'almost', 'fourth', 'behind', 'damage', 'least', '26', 'brown', 'party', 'ten', 'added', 'heavy', 'followed', 'months', 'appeared', 'wife', 'killed', 'addition', 'does', 'playing', 'success', 'awards', 'list', 'features', 'aircraft', '2003', 'coast', 'sea', 'taken', '2015', 'david', 'leading', 'championship', 'action', 'france', 'either', 'europe', 'front', 'recording', 'served', 'towards', 'campaign', 'operations', 'gold', 'mother', 'put', 'decided', 'elements', 'close', 'records', 'believed', 'fleet', 'generally', 'magazine', 'carey', 'ever', 'female', 'post', 'poem', 'sold', 'soon', 'example', 'infantry', 'points', 'significant', 'fort', 'goal', 'move', 'weeks', 'rather', 'study', 'european', 'federer', 'outside', 'o', 'opened', 'robert', 'case', 'directed', 'brought', 'help', 'law', 'non', 'finished', '27', 'earlier', 'wales', 'william', 'featured', 'go', 'get', 'victory', 'manager', 'successful', 'act', 'gun', 'stage', 'association', 'member', 'provided', 'mi', 'mid', 'opening', 'start', 'village', 'working', 'council', 'wanted', 'appearance', 'jordan', 'particularly', 'roman', 'troops', '2014', '40', 'atlantic', 'depression', 'initially', 'tech', '29', 'evidence', 'yard', 'far', 'find', 'largest', 'office', 'blue', 'dam', 'george', 'review', 'attempt', 'possible', 'saw', 'special', 'type', 'month', 'summer', '19th', 'above', 'union', 'yards', 'e', 'florida', 'rest', 'allowed', 'event', 'race', 'winds', 'critical', 'saying', 'creek', 'cross', 'hours', 'whom', 'nine', '2001', 'missouri', 'plan', 'police', 'worked', 'community', 'designed', 'reception', 'society', '500', 'previously', 'free', 'forced', 'middle', 'process', 'era', 'operation', 'radio', 'real', 'remains', '200', 'increased', 'official', 'praised', 'research', 'hall', 'lower', 'parliament', 'station', 'come', 'michael', 'relationship', 'command', 'commander', 'hill', 'regiment', 'studio', 'units', 'base', 'taking', '£', 'parts', 'replaced', 'writer', 'ball', 'industry', 'media', 'navy', 'social', 'food', 'r', 'bay', 'co', 'college', 'highest', 'reviews', 'beginning', 'claimed', 'don', '°', 'canada', 'estimated', 'mph', 'museum', 'section', 'goals', 'stone', 'average', 'commercial', 'japanese', 'joined', 'l', 'religious', 'involved', 'oldham', 'placed', 'stories', 'training', 'introduced', 'met', 'shot', 'signed', 'suggested', 'lines', 'sometimes', '31', 'background', 'business', 'face', 'olivier', 'paul', 'today', 'complete', 'going', 'itself', 'scene', 'henry', 'mexico', 'structure', 'additional', 'available', 'give', 'thus', 'cast', 'date', 'horse', 'language', 'loss', 'india', 'nearly', 'sound', 'term', 'whose', 'fifth', 'past', 'thomas', 'approximately', 'indian', 'irish', 'must', 'program', 'already', 'appointed', 'capital', 'entire', 'friends', 'britain', 'damaged', 'native', 'prior', 'shows', 'told', 'forest', 'issue', 'mark', 'names', 'probably', 'turned', 'male', 'sun', 'winning', '-', 'change', 'g', 'our', 'students', '?', 'earth', 'length', 'passed', 'size', 'child', 'civil', 'especially', 'christian', 'enough', 'notes', 'woman', 'chinese', 'failed', 'forward', 'mixed', 'overall', 'running', 'better', 'captain', 'ny', '2002', 'limited', 'future', 'iii', 'minor', 'network', 'arrived', 'changes', 'includes', 'might', 'moving', 'ordered', 'pacific', 'regular', 'spent', 'wheeler', 'canadian', 'cathedral', 'education', 'larger', 'remaining', 'usually', 'birds', 'department', 'hand', 'hit', 'lake', 'required', 'san', 'uk', 'decision', 'latter', 'africa', 'plot', 'response', '2000', 'musical', 'round', 'space', 'voice', 'wide', 'appear', 'crew', 'debut', 'groups', 'mounted', 'related', 'centre', 'jin', 'rachel', 'territory', 'view', '00', 'billboard', 'ended', 'feature', 'films', 'nature', 'positive', 'saint', 'science', 'culture', 'finally', 'flight', 'score', 'squadron', 'supported', 'becoming', 'money', 'pressure', 'always', 'books', 'charles', 'provide', 'smaller', '1995', 'anti', 'discovered', 'private', 'shown', 'board', 'minutes', 'particular', 'shortly', 'defeated', 'difficult', 'experience', 'mass', 'nations', 'person', 'peter', 'temple', 'trade', 'big', 'staff', 'subsequently', 'surface', 'effects', 'japan', 'lack', 'living', 'press', 'upper', 'zealand', 'professional', 'word', 'fact', 'greater', 'material', 'tv', '60', 'problems', 'room', 'self', 'teams', 'bridge', 'collection', 'cut', 'gods', 'idea', 'intended', 'interest', 'key', 'largely', 'news', 'numbers', 'scientology', 'cover', 'haifa', 'metres', 'mostly', 'primary', 'themselves', '2016', 'captured', 'cm', 'got', 'likely', 'machine', 'mountain', 'referred', 'traffic', 'xenon', 'yet', 'contract', 'entered', 'location', 'tower', 'whole', 'airport', 'bill', 'makes', 'square', 'constructed', 'contains', 'greatest', 'headquarters', 'listed', 'lyrics', 'majority', 'morning', 'ranked', '1999', 'leaving', 'starting', 'wall', 'information', 'natural', 'report', 'studies', 'v', 'whether', 'companies', 'competition', 'election', 'officers', 'poor', '45', 'create', 'deal', 'fighting', 'galveston', 'certain', 'changed', 'fans', 'unit', 'dead', 'episodes', 'forms', 'jack', 'jewish', 'pass', 'proposed', 'theme', 'agreed', 'influence', 'know', 'lived', 'personal', 'plans', 'soldiers', 'turn', '2nd', 'california', 'increase', 'launched', 'movement', 'runs', 'singles', 'compared', 'concert', 'current', 'direct', 'friend', 'independent', 'pre', 'quarter', 'quickly', 'lady', 'minute', 'occurred', 'queen', 'richard', 'trees', 'valley', 'villa', 'assigned', 'health', 'leave', 'sixth', 'things', 'true', 'appears', 'artillery', 'condoms', 'defeat', 'destroyed', 'hot', 'inside', 'ocean', 'services', 'traditional', 'chicago', 'contemporary', 'double', 'longer', 'schools', 'takes', 'tons', 'artist', 'asked', 'cause', 'alice', 'awarded', 'carried', 'cyclone', 'proteins', 'source', '1998', 'buildings', 'conducted', 'daughter', 'ending', 'interview', 'latin', 'marriage', 'something', 'writers', 'ancient', 'annual', 'associated', 'burns', 'district', 'status', 'empire', 'f', 'ran', '1993', 'albums', 'alkan', 'commented', 'conference', 'married', 'polish', 'unable', '+', 'brother', 'corps', 'image', 'liverpool', 'nixon', 'numerous', 'republic', 'scenes', '1st', '400', 'deep', 'producer', 'standard', 'done', 'inspired', 'management', 'meaning', 'minister', 'positions', 'texas', 'attacks', 'somerset', 'terms', 'tracks', 'defense', 'earned', 'mosley', 'piano', '1996', '20th', 'begins', 'bird', 'broadcast', 'busch', 'daily', 'dark', 'giving', 'initial', 'issued', 'la', 'peak', 'planned', 'stay', 'variety', '80', 'actor', 'bowl', 'committee', 'directly', 'green', 'historical', 'immediately', 'nuclear', 'performances', 'via', 'your', 'castle', 'christmas', 'figure', 'individual', 'ross', 'spanish', 'taylor', 'al', 'coach', 'fowler', 'fox', 'helped', 'organization', 'wing', 'african', 'blood', 'effect', 'suffered', '38', 'chief', 'meant', 'nearby', 'safe', 'uses', '75', 'author', 'closed', 'cultural', 'presented', 'really', 'think', '35', 'girl', 'presence', 'raised', 'twenty', 'vocals', 'attempts', 'carolina', 'continue', 'figures', 'k', 'reach', 'rule', 'virginia', 'below', 'cell', 'covered', 'federal', 'super', 'assembly', 'call', 'catholic', 'composed', 'marked', 'officer', 'selected', '1997', 'appearances', 'beyoncé', 'bodies', 'course', 'extended', 'higher', '300', 'advance', 'countries', 'el', 'fell', 'germany', 'hard', 'here', 'miami', 'needed', 'offensive', 'camp', 'fiction', 'places', 'situation', 'speed', 'arts', 'attacked', 'comedy', 'festival', 'highly', 'hour', 'los', 'pop', 'recent', 'cadmium', 'edge', 'pennsylvania', 'protein', 'singer', 'specific', 'want', 'academy', 'allowing', 'distance', 'edition', 'energy', 'movie', 'paris', 'removed', 'tradition', 'active', 'baby', 'hold', 'hospital', 'levels', 'metal', 'offered', 'peaked', 'prince', 'scotland', 'subject', 'theatre', 'widely', '1991', 'attempted', 'chris', 'combined', 'copies', 'fall', 'governor', 'means', 'meeting', 'percent', 'powerful', 'rate', 'typically', 'allow', 'china', 'hands', 'iron', 'respectively', 'responsible', 'scoring', 'themes', 'activities', 'anderson', 'boy', 'describes', 'genus', 'husband', 'islands', 'need', 'sister', '1992', 'birth', 'combat', 'complex', 'formation', 'heavily', 'houses', 'le', 'mile', 'observed', 'sets', '1994', 'car', 'condom', 'looking', 'parents', 'reduced', 'rights', 'armed', 'audience', 'concluded', 'defence', 'jackson', 'mary', 'matches', 'minnesota', 'quality', 'resulted', 'stop', 'wind', 'activity', 'beach', 'calling', 'clear', 'completely', 'conditions', 'cost', 'kakapo', 'reports', 'residents', 'strength', '3rd', 'efforts', 'featuring', 'j', 'managed', 'revealed', 'rosebery', 'stadium', 'stating', 'townsend', 'transport', 'wave', 'account', 'artists', 'cricket', 'declared', 'description', 'draw', 'finals', 'look', 'refused', 'relief', 'separate', '1970', 'finkelstein', 'independence', 'leg', 'meyerbeer', 'therefore', 'van', 'walpole', 'approach', 'casualties', 'coming', 'emperor', 'impact', 'naval', 'sales', 'seasons', 'security', 'shiva', 'tessa', 'titles', '70', 'actions', 'expected', 'foreign', 'issues', 'nicole', 'ottoman', 'sports', 'yue', 'attention', 'becomes', 'follow', 'mainly', 'mount', 'plays', 'practice', 'words', 'braathens', 'italian', 'pair', 'scale', 'soundtrack', 'tournament', 'actually', 'eye', 'letters', 'lord', 'primarily', 'ultimately', '1990', 'accepted', 'achieved', 'cannot', 'critic', 'hotel', 'johnson', 'master', 'roles', 'spring', 'struck', 'write', 'authority', 'colony', 'concept', 'entertainment', 'fight', 'foundation', 'fully', 'job', 'paper', 'portuguese', 'silver', 'sir', 'weather', '36', 'alone', 'alongside', 'amount', 'antimony', 'authorities', 'channel', 'flooding', 'legal', 'northeast', 'rainfall', 'sense', 'sequence', 'serious', 'smith', 'soviet', 'workers', '1986', 'battery', 'branch', 'broken', 'elected', 'link', 'newspaper', 'owned', 'remain', 'slightly', 'affected', 'data', 'defensive', 'expressed', 'foot', 'inches', 'males', 'opera', 'ridge', 'spain', 'standing', 'twice', 'access', 'disease', 'except', 'fey', 'flying', 'frank', 'mission', 'officials', 'say', 'showed', 'vietnam', 'ability', 'commission', 'fish', 'fruit', 'historic', 'northwest', 'tintin', 'toward', 'varanasi', 'welsh', 'zhou', '33', '90', 'meet', 'nesbitt', 'physical', 'titled', 'acting', 'angeles', 'composition', 'computer', 'continues', 'domestic', 'earliest', 'eva', 'financial', 'individuals', 'israel', 'lives', 'mentioned', 'n', 'odaenathus', 'prevent', 'produce', 'says', 'sites', 'visit', '39', 'adopted', 'bank', 'cities', 'dumont', 'engineer', 'founded', 'influenced', 'market', 'olympic', 'perfect', 'read', 'reign', 'resulting', 'sarnia', 'singing', '150', 'advantage', 'analysis', 'basis', 'dedicated', 'digital', 'executive', 'illinois', 'increasing', 'keep', 'mr', 'officially', 'rear', 'represented', 'script', 'sources', 'sr', 'tree', 'winter', 'begin', 'direction', 'doing', 'heart', 'lot', 'manchester', 'reason', 'studios', 'surrounding', 'viewers', 'aid', 'faced', 'maximum', 'medical', 'peace', 'relatively', 'secret', 'sides', 'washington', '18th', '1988', 'attended', 'build', 'capture', 'chapel', 'females', 'freeway', 'journey', 'losing', 'older', 'organized', 'potential', 'test', 'transferred', 'tried', 'types', 'alabama', 'beyond', 'drive', 'effort', 'meanwhile', 'notable', 'oil', 'omaha', 'piece', 'proved', 'student', 'thick', 'unlike', '47', 'animal', 'archaeological', 'believe', 'boat', 'break', 'charge', 'literature', '1960s', 'baseball', 'ceres', 'charts', 'conflict', 'designated', 'divided', 'fly', 'focus', 'follows', 'golden', 'helms', 'institute', 'intensity', 'kind', 'model', 'mogadishu', 'nation', 'perón', 'possibly', 'results', 'yellow', '1940', '1964', '1980s', 'arms', 'bishop', 'border', 'core', 'dance', 'determined', 'edward', 'historian', 'images', 'innis', 'paid', 'planet', 'prime', 'returning', 'shape', 'simply', 'structures', 'supporting', 'treaty', 'w', 'wilhelm', 'am', 'box', 'creation', 'dr', 'economic', 'entrance', 'equipment', 'growing', 'joseph', 'kept', 'onto', 'portion', 'rose', 'rugby', 'technology', 'underground', 'argued', 'filming', 'importance', 'kg', 'knowledge', 'mccall', 'promotion', 'railway', 'rare', 'secretary', 'weekly', 'baltimore', 'bob', 'buried', 'currently', 'grew', 'hamels', 'landing', 'lane', 'note', 'playstation', 'projects', 'publication', 'rihanna', 'sexual', 'suggests', 'actress', 'advanced', 'breeding', 'campus', 'causing', 'couple', 'criticized', 'escape', 'gained', 'hair', 'letter', 'lock', 'orders', 'pay', 'reference', 'volume', 'website', '5th', 'claims', 'containing', 'crown', 'debuted', 'djedkare', 'draft', 'guest', 'homes', 'horses', 'jupiter', 'p', 'property', 'reaching', 'reaction', 'rise', 'travel', 'x', '1947', '32', 'administration', 'andrew', 'chosen', 'contrast', 'enemy', 'leader', 'personnel', 'religion', 'theory', 'torres', 'abandoned', 'ahead', 'care', 'cases', 'consecutive', 'granted', 'inch', 'newly', 'prominent', 'rejected', 'seems', 'unknown', '1941', 'applewhite', 'assault', 'cells', 'color', 'commonly', 'content', 'crazy', 'deities', 'increasingly', 'multiple', 'pine', 'scottish', 'secondary', 'settlement', 'visited', '1987', 'broke', 'growth', 'haven', 'lands', 'moment', 'passing', 'regions', 'risk', 'seconds', 'systems', 'touchdown', 'wounded', '1970s', 'beat', 'egyptian', 'fantasy', 'feel', 'identified', 'killing', 'nominated', 'promoted', 'revolution', 'screen', 'senior', 'solo', 'temperature', 'thing', 'versions', '1972', '1984', '1989', '9th', 'agreement', 'aired', 'anonymous', 'barrow', 'bbc', 'croatia', 'dvd', 'fame', 'famous', 'greek', 'opposed', 'roads', 'save', 'selling', 'stations', 'unique', '1985', '4th', 'animals', 'bass', 'choice', 'fired', 'hope', 'mike', 'mouth', 'nothing', 'operated', 'outer', 'share', '1960', 'adult', 'boats', 'cardiff', 'confirmed', 'cougar', 'drama', 'explained', 'filmed', 'hms', 'ideas', 'poetry', 'serve', 'sport', 'subsequent', 'visual', 'writes', '1944', 'consisted', 'controlled', 'families', 'gives', 'herself', 'invasion', 'michigan', 'murder', 'ode', 'offer', 'perform', 'philadelphia', 'rapidly', 'regarded', 'vocal', 'weapons', '1990s', 'actors', 'aspects', 'avoid', 'battalions', 'bond', 'depth', 'dropped', 'failure', 'flow', 'keats', 'maintained', 'pieces', 'premier', 'seventh', 'slam', 'trial', 'wood', 'chains', 'extensive', 'injury', 'landfall', 'occur', 'phase', 'pitched', 'province', 'ray', 'urban', '600', 'ai', 'andy', 'bring', 'claim', 'criticism', 'gulf', 'humans', 'italy', 'km2', 'medieval', 'retired', 'search', 'sign', 'steve', 'sustained', 'tom', 'transit', 'truth', 'value', 'abu', 'americans', 'bid', 'connected', 'creating', 'facilities', 'finding', 'hundred', 'interchange', 'passes', 'recognized', 'semi', 'significantly', 'try', 've', 'weight', 'why', 'chose', 'intelligence', 'matter', 'necessary', 'perhaps', 'popularity', 'producers', 'protection', 'scheduled', 'sought', 'spread', 'stones', 'walls', '1981', 'cited', 'comic', 'generation', 'height', 'laid', 'losses', 'nucleus', 'powers', 'recently', 'represent', 'stand', 'starts', 'treatment', 'vietnamese', 'wild', 'bad', 'chapter', 'dated', 'employed', 'fought', 'gradually', 'nathan', 'regarding', 'request', 'sex', 'southeast', 'thunderbirds', '1939', 'comes', 'conservation', 'contained', 'distribution', 'ends', 'finds', 'frequently', 'guard', 'policy', 'prepared', 'rating', 'safety', 'transfer', '17th', '1942', 'allows', 'athletes', 'bc', 'champion', 'cold', 'collected', 'contributed', 'degree', 'gordon', 'habitat', 'host', 'jim', 'memorial', 'negative', 'oxford', 'peninsula', 'serving', 'severe', 'vice', 'worldwide', '1918', '1950s', '34', 'championships', 'commissioned', 'concrete', 'dynasty', 'economy', 'effective', 'entirely', 'gameplay', 'improved', 'kill', 'lieutenant', 'lisa', 'nba', 'neither', 'pilot', 'problem', 'shaped', 'survey', 'turner', '1968', '1969', '51', 'arab', 'boise', 'boston', 'budget', 'contain', 'drawn', 'dutch', 'europium', 'folk', 'gain', 'kilometres', 'let', 'lewis', 'mario', 'motion', 'path', 'reasons', 'sentence', 'setting', 'shell', 'simple', 'slowly', 'text', 'threat', 'williams', '1975', 'bottom', 'canal', 'dates', 'decade', 'develop', 'expanded', 'extra', 'gully', 'planning', 'programs', 'roughly', 'russian', 'stages', 'supply', '12th', '1965', '1974', '37', '44', 'allied', 'appeal', 'centuries', 'display', 'dota', 'evening', 'evita', 'girls', 'glass', 'items', 'join', 'massive', 'occasionally', 'occupied', 'pope', 'rich', 'southwest', 'transportation', 'youth', '42', 'additionally', 'churches', 'deaths', 'decades', 'dollar', 'editor', 'experienced', 'floor', 'jane', 'khánh', 'miss', 'nor', 'plant', 'quite', 'rain', 'sector', 'speaking', 'straight', 'successfully', 'train', 'violence', 'waters', '700', 'avenue', 'bar', 'didn', 'die', 'dress', 'engaged', 'ice', 'jamal', 'poet', 'purchased', 'tell', 'wedding', '1946', '48', 'attorney', 'authors', 'begun', 'brian', 'briefly', 'category', 'declined', 'details', 'drew', 'learned', 'martin', 'permanent', 'politics', 'remix', 'tail', 'tennyson', 'torpedo', '1950', '800', 'adding', 'applied', 'basin', 'congress', 'des', 'eyes', 'fur', 'guide', 'interior', 'leaders', 'literary', 'liu', 'marine', 'moves', 'nest', 'normal', 'performing', 'settlers', 'simone', 'slow', 'thirty', 'zone', '#', '1919', '1952', '1966', '49', 'accompanied', 'acres', 'arrival', 'bell', 'cap', 'condition', 'discovery', 'earthquake', 'enjoyed', 'fields', 'happy', 'hired', 'holy', 'jump', 'justice', 'longest', 'paintings', 'participated', 'possibility', 'responded', 'routes', 'scholars', '1936', '53', 'ad', 'ali', 'brothers', 'characteristics', 'contact', 'developing', 'egypt', 'engineering', 'heads', 'heard', 'journal', 'macleod', 'mind', 'oldest', 'painting', 'purpose', 'skin', 'snow', 'technical', 'ulysses', '1930', '1973', '64', 'anthony', 'apart', 'biography', 'charter', 'chorus', 'coastal', 'combination', 'consists', 'crowd', 'dominated', 'enter', 'existence', 'fellow', 'funding', 'goes', 'imperial', 'joint', 'lasted', 'max', 'populations', 'reserve', 'reviewers', 'thousands', 'towns', 'turkish', 'typical', 'widespread', 'younger', '1967', 'anything', 'calls', 'cardinal', 'caught', 'chance', 'closely', 'clubs', 'competitions', 'crime', 'dog', 'engine', 'everything', 'existing', 'hip', 'juan', 'kang', 'missing', 'monument', 'mountains', 'reality', 'stopped', 'turning', 'weakened', '1914', '1930s', '65', 'assistant', 'billion', 'capable', 'ceremony', 'classic', 'creator', 'decline', 'derived', 'element', 'exist', 'greatly', 'holding', 'legacy', 'moon', 'noisy', 'opportunity', 'provides', 'rules', 'serves', 'similarly', 'tells', 'trip', 'wins', 'aml', 'bought', 'caribbean', 'chelsea', 'dissipated', 'douglas', 'filled', 'gas', 'grade', 'headed', 'hornung', 'industrial', 'innings', 'invited', 'jazz', 'locations', 'md', 'palace', 'priest', 'rail', 'reading', 'receiving', 'restaurant', 'ring', 'rolling', 'seat', 'storyline', 'task', 'technique', 'vehicles', '1945', '1971', '6th', 'asia', 'classified', 'colonel', 'constantine', 'describing', 'destiny', 'establish', 'establishment', 'evil', 'falls', 'hibari', 'louis', 'maeda', 'mean', 'novels', 'perry', 'question', 'ratings', 'receive', 'rural', 'survived', 'sweet', 'viewed', 'ways', '1982', 'acquired', 'boys', 'champions', 'converted', 'dry', 'eagle', 'entry', 'everglades', 'faith', 'flights', 'formula', 'ga', 'georgian', 'grant', 'library', 'mortal', 'mtv', 'romani', 'scott', 'shared', 'simon', 'teaching', 'trying', 'von', 'whereas', '1913', '1916', '1956', '1976', '1980', 'arranged', 'atmosphere', 'brief', 'carry', 'chemical', 'clean', 'depicted', 'eighth', 'electronic', 'engineers', 'entering', 'fine', 'finish', 'focused', 'haiti', 'label', 'mushroom', 'ones', 'opposition', 'oslo', 'poems', 'regional', 'rescue', 'rio', 'rivers', 'spacing', 'store', 'succeeded', 'vision', 'watched', '1943', '8th', 'agent', 'article', 'assistance', 'attached', 'basketball', 'communist', 'credited', 'credits', 'defined', 'iguanodon', 'jones', 'knew', 'methods', 'penalty', 'prize', 'providing', 'siege', 'sky', 'venus', '10th', '1963', '41', '43', 'adapted', 'civilian', 'colonies', 'controversy', 'dating', 'delivered', 'dublin', 'examples', 'fear', 'hits', 'ign', 'incident', 'jain', 'jersey', 'kent', 'method', 'morrison', 'professor', 'rangers', 'rarely', 'renamed', 'rome', 'separated', 'supplies', 'tied', 'accounts', 'acid', 'alexander', 'archaeology', 'athletic', 'australians', 'bradford', 'camps', 'certified', 'classes', 'colonial', 'columbia', 'commanded', 'consisting', 'fountain', 'fuel', 'hollywood', 'indicate', 'opinion', 'pattern', 'progress', 'protect', 'protected', 'regime', 'remainder', 'strike', 'sunday', 'usa', 'utc', '16th', '1953', '1978', '55', 'chairman', 'croatian', 'divine', 'drop', 'facing', 'feelings', 'fun', 'grey', 'hearts', 'inner', 'introduction', 'maryland', 'memory', 'montana', 'narrow', 'occurs', 'online', 'references', 'specifically', 'suggest', 'tests', 'threatened', 'trujillo', 'turns', 'window', '11th', '56', 'acts', 'agricultural', 'alan', 'alternative', 'appearing', 'arthur', 'cd', 'charlie', 'communities', 'denied', 'desire', 'divisions', 'exit', 'favorite', 'feeling', 'finishing', 'function', 'gray', 'leads', 'leaves', 'masters', 'missions', 'mississippi', 'portrayed', 'producing', 'protest', 'recognition', 'reputation', 'roxas', 'shooting', 'soil', 'spirit', 'squad', 'statement', 'studied', 'successor', 'views', 'walter', 'wooden', 'worship', '−', '1915', '250', '7th', '96', 'activision', 'arsenal', 'basic', 'daniel', 'dismissed', 'duke', 'fictional', 'gallery', 'getting', 'hindu', 'homer', 'honor', 'howard', 'kings', 'lords', 'maintain', 'message', 'offense', 'outstanding', 'picture', 'principal', 'reviewer', 'rifles', 'samuel', 'secure', 'seeing', 'supreme', 'worst', 'academic', 'attributed', 'calvert', 'capacity', 'changing', 'charges', 'chess', 'continuing', 'discussed', 'dollars', 'drawing', 'enterprise', 'holds', 'interested', 'involvement', 'isabella', 'knots', 'measure', 'noting', 'opponents', 'replace', 'specimens', 'speech', 'steel', 'target', 'tomb', 'watch', '1917', '1948', 'adventure', 'bart', 'bit', 'challenge', 'count', 'counter', 'danny', 'distinct', 'dna', 'exchange', 'expedition', 'fa', 'flank', 'flood', 'global', 'inland', 'magic', 'mix', 'nbc', 'offers', 'origin', 'passage', 'railroad', 'ruled', 'sarajevo', 'session', 'solid', 'standards', 'theater', 'towers', 'twelve', 'wars', '120', '1951', '1979', '94', 'coal', 'considerable', 'difficulty', 'emotional', 'faces', 'forests', 'frederick', 'gate', 'guardian', 'labour', 'miner', 'ninth', 'none', 'plants', 'prey', 'rocky', 'romantic', 'signing', 'someone', 'stephen', 'strand', 'victoria', 'yankovic', '1954', '1961', '54', '61', '95', 'aston', 'breaking', 'brigades', 'candidate', 'clarkson', 'crossing', 'firm', 'heritage', 'hills', 'historians', 'joe', 'landed', 'mine', 'mode', 'nomination', 'observations', 'pitch', 'races', 'raid', 'relationships', 'replacement', 'somali', 'taught', '1937', 'adults', 'agency', 'believes', 'bono', 'brien', 'bringing', 'connection', 'destroyers', 'documentary', 'estate', 'francisco', 'fungus', 'intersection', 'jifna', 'kitsune', 'lee', 'marines', 'muslim', 'nightingale', 'picked', 'recommended', 'rooms', 'santa', 'secured', 'simpsons', 'skye', 'soul', 'teacher', 'wilde', '1955', '52', 'adams', 'alien', 'argentina', 'classical', 'concerns', 'door', 'extremely', 'fashion', 'fit', 'genre', 'gone', 'grow', 'hamilton', 'languages', 'launch', 'leadership', 'learning', 'legs', 'll', 'missed', 'multi', 'nc', 'nevertheless', 'olympics', 'op', 'organizations', 'partial', 'respect', 'sections', 'shore', 'split', 'streets', 'surviving', 'territories', 'throw', 'windows', '×', '1958', 'approached', 'arrangement', 'banai', 'commonwealth', 'compounds', 'detailed', 'diameter', 'distributed', 'electric', 'emerged', 'encouraged', 'existed', 'extreme', 'manner', 'marks', 'parties', 'ruler', 'showing', 'sons', 'surrounded', 'talk', 'teeth', 'tribes', 'tries', '1949', '1977', '3d', '46', 'admiral', 'apparent', 'armor', 'attempting', 'carter', 'climate', 'constitution', 'counties', 'courts', 'crossed', 'dream', 'fan', 'firing', 'freedom', 'fresh', 'giant', 'ha', 'hoped', 'immediate', 'inspiration', 'institutions', 'isolated', 'lennon', 'plain', 'regularly', 'rival', 'roger', 'suffering', 'triple', 'tunnel', 'unusual', 'videos', 'wants', '13th', '62', 'admitted', 'anniversary', 'assumed', 'bolívar', 'convoy', 'designation', 'duties', 'expansion', 'footage', 'franchise', 'goffman', 'hergé', 'hundreds', 'identity', 'indeed', 'initiative', 'janeiro', 'kilmer', 'laws', 'neck', 'owner', 'pointed', 'possession', 'protagonist', 'protests', 'rapid', 'reconstruction', 'relative', 'resources', 'ryan', 'saprang', 'scientific', 'sequel', 'sessions', 'statistics', 'strongly', 'tales', 'treated', 'verse', 'visible', 'weak', '1920', '1983', '85', 'accept', 'aged', 'airline', 'approved', 'attracted', 'bce', 'belt', 'camera', 'christ', 'completion', 'concerned', 'concerts', 'coup', 'cycle', 'debate', 'easily', 'eggs', 'fixed', 'frame', 'georgia', 'heaven', 'hop', 'improve', 'indicated', 'internal', 'jerusalem', 'lawton', 'medal', 'meets', 'mention', 'musicians', 'pleasure', 'reconnaissance', 'specimen', 'spot', 'trials', 'warm', 'wearing', 'wimbledon', 'winner', 'accused', 'adjacent', 'amateur', 'behaviour', 'burn', 'cambridge', 'composer', 'crash', 'destruction', 'dramatic', 'effectively', 'falling', 'gerard', 'ghost', 'guy', 'hear', 'incorporated', 'influences', 'jean', 'looked', 'ministry', 'norman', 'parks', 'pool', 'practices', 'prison', 'publishing', 'rated', 'recordings', 'register', 'remnants', 'require', 'richardson', 'rifle', 'ritual', 'sand', 'settled', 'somalia', 'starling', 'surrender', 'tall', 'tank', 'terminus', 'traveled', 'watershed', '1909', '1910', 'adam', 'afterwards', 'ages', 'aniston', 'anzac', 'arc', 'aviation', 'bridges', 'destroy', 'driving', 'eleven', 'environment', 'holiday', 'jesus', 'keamy', 'kombat', 'measures', 'meetings', 'mega', 'mole', 'obtained', 'operating', 'painted', 'partly', 'pitcher', 'portrait', 'pupils', 'purchase', 'recalled', 'recovered', 'restoration', 'roll', 'seemed', 'selection', 'shots', 'solar', 'somewhat', 'stands', 'storms', 'supposed', 'un', 'victims', 'worth', '1912', '1931', '1935', 'arabic', 'architecture', 'au', 'cake', 'cancer', 'corn', 'corythosaurus', 'craft', 'crisis', 'desert', 'destroyer', 'distinguished', 'fast', 'fraser', 'funds', 'germans', 'hosted', 'household', 'johnston', 'lb', 'linked', 'normally', 'origins', 'plunketts', 'poland', 'preserved', 'reduce', 'representing', 'researchers', 'sculpture', 'stevens', 'table', 'tone', 'township', 'trail', '1932', '76', 'artificial', 'attacking', 'ben', 'blocks', 'circulation', 'colour', 'controversial', 'covering', 'covers', 'crosses', 'dean', 'defended', 'else', 'elsewhere', 'equipped', 'expensive', 'express', 'fia', 'forming', 'generals', 'grass', 'hockey', 'hunting', 'income', 'institution', 'interaction', 'judge', 'junior', 'marlborough', 'medium', 'monuments', 'nintendo', 'opposite', 'prerogative', 'pro', 'programme', 'responsibility', 'shoot', 'sisters', 'stayed', 'tailed', 'trading', 'vessel', 'wolf', '1911', '1921', '1929', 'arrested', 'beautiful', 'burning', 'cave', 'cloud', 'consider', 'disaster', 'disc', 'essential', 'exception', 'fate', 'fei', 'impossible', 'internet', 'lawrence', 'legend', 'legislation', 'lowest', 'mill', 'mobile', 'netherlands', 'otherwise', 'owen', 'parallel', 'passengers', 'patrick', 'plum', 'promote', 'pushed', 'rebels', 'sing', 'speak', 'stanley', 'step', 'supporters', 'throwing', 'voted', 'wine', 'wrong', '1938', '1959', '1962', '57', '81', 'atlanta', 'batsman', 'block', 'bone', 'bright', 'cambodia', 'carrying', 'cemetery', 'charity', 'citing', 'comments', 'convention', 'criminal', 'cruiser', 'defences', 'difficulties', 'earl', 'elizabeth', 'equivalent', 'garcía', 'gates', 'graph', 'helmet', 'intensified', 'involving', 'iv', 'korean', 'lap', 'learn', 'motor', 'objects', 'observatory', 'occasions', 'panel', 'pitman', 'praise', 'quick', 'raise', 'retained', 'returns', 'roof', 'stefani', 'tribute', 'understanding', 'unsuccessful', 'vessels', 'villages', '1900', '1920s', '66', 'ace', 'aerith', 'allah', 'apparently', 'behavior', 'belief', 'biographer', 'bound', 'canterbury', 'causes', 'cbs', 'choir', 'committed', 'context', 'cult', 'defeating', 'democratic', 'drum', 'fallen', 'farm', 'housing', 'ill', 'laboratory', 'latex', 'mediterranean', 'narrative', 'needs', 'notably', 'overseas', 'palestine', 'periods', 'phillies', 'preferred', 'princess', 'product', 'resistance', 'reveals', 'saved', 'sees', 'sell', 'slide', 'subspecies', 'survivors', 'tale', 'temples', 'voiced', 'wings', '110', '71', 'absence', 'bureau', 'canyon', 'closer', 'collaboration', 'colorado', 'considers', 'criticised', 'deployed', 'dialogue', 'doesn', 'exposure', 'followers', 'formally', 'furtado', 'grammy', 'imagine', 'journalist', 'kick', 'lbw', 'manga', 'maria', 'markgraf', 'mayor', 'monarch', 'musician', 'platoon', 'productions', 'products', 'proposal', 'raffles', 'ready', 'refers', 'representative', 'represents', 'shipping', 'steam', 'suggesting', 'tie', 'trust', 'u2', 'visitors', 'warning', 'aftermath', 'altar', 'amino', 'archbishop', 'aware', 'carol', 'communications', 'convection', 'da', 'depending', 'directors', 'displays', 'dock', 'dominican', 'drums', 'ensure', 'extent', 'flat', 'heat', 'moments', 'muscaria', 'networks', 'nhl', 'poorly', 'predators', 'ranges', 'recovery', 'republican', 'sacred', 'sale', 'sholay', 'stable', 'stationed', 'submarine', 'thereafter', 'trouble', 'universal', 'vehicle', 'waterfall', '15th', '1940s', '98', 'accident', 'advertising', 'annually', 'assist', 'baker', 'cape', 'cat', 'childhood', 'clay', 'coins', 'doubt', 'driven', 'entitled', 'environmental', 'excavation', 'extension', 'fifa', 'garden', 'influential', 'infrastructure', 'injuries', 'intense', 'lists', 'lose', 'maggie', 'mexican', 'models', 'modified', 'municipal', 'opportunities', 'orbit', 'posted', 'publisher', 'purposes', 'radiation', 'regard', 'representatives', 'saves', 'scholar', 'simultaneously', 'situated', 'superior', 'talking', 'thousand', 'throne', 'withdraw', 'withdrew', '1928', '72', '77', 'adventures', 'ago', 'ammunition', 'anime', 'athletics', 'barker', 'burned', 'circumstances', 'dawn', 'demand', 'detail', 'driver', 'easy', 'en', 'engines', 'factors', 'generated', 'happened', 'historically', 'informed', 'installed', 'interests', 'israeli', 'massachusetts', 'materials', 'norway', 'originated', 'parvati', 'pick', 'plane', 'platform', 'properties', 'rates', 'relations', 'réunion', 'severely', 'shark', 'spoke', 'watching', 'wrestling', 'writings', 'z', '1927', '59', 'affairs', 'agents', 'amongst', 'anekāntavāda', 'anyone', 'biggest', 'bulls', 'carved', 'casting', 'dangerous', 'dc', 'deck', 'departure', 'eaton', 'emergency', 'everyone', 'favor', 'gary', 'gwen', 'hurricanes', 'instruments', 'kannada', 'layer', 'map', 'mixture', 'movements', 'operate', 'option', 'organ', 'partially', 'plateau', 'pole', 'portugal', 'proper', 'raaf', 'rhythm', 'richmond', 'shells', 'starlings', 'stem', 'substantial', 'survive', 'swedish', 'sword', 'ustaše', 'victories', 'walk', 'whilst', 'wilson', '1933', 'armored', 'bearing', 'boxing', 'broad', 'caves', 'chamber', 'citizens', 'classification', 'compete', 'corporation', 'creative', 'diet', 'documents', 'downtown', 'establishing', 'fifteen', 'forty', 'howe', 'instance', 'interesting', 'khandoba', 'listing', 'looks', 'loose', 'midge', 'márquez', 'object', 'occupation', 'personality', 'premiered', 'price', 'reinforcements', 'residence', 'resigned', 'restored', 'rising', 'sang', 'sequences', 'simpson', 'spend', 'spores', 'stewart', 'struggle', 'sung', 'techniques', 'terrorist', 'thinking', 'twins', 'usd', 'veronica', 'wasn', 'wicca', 'wives', '1957', '21st', 'achieve', 'actual', 'application', 'arm', 'bath', 'bush', 'catechism', 'continental', 'correct', 'dan', 'designs', 'detroit', 'experiences', 'flower', 'forcing', 'frelimo', 'grounds', 'hart', 'illustrated', 'inhg', 'jeff', 'jr', 'jurchen', 'martial', 'matt', 'mental', 'miller', 'minimum', 'moderate', 'mozambique', 'mulder', 'offices', 'page', 'phoenix', 'preparation', 'prove', 'readers', 'recognised', 'resolution', 'retirement', 'ride', 'saturday', 'scientists', 'shakespeare', 'sounds', 'sub', 'toronto', 'universe', 'useful', 'vary', 'wasp', 'wright', 'zoo', '900', 'address', 'archaeologist', 'bear', 'cars', 'characterized', 'cleared', 'coleman', 'convinced', 'costs', 'cubs', 'delayed', 'depicts', 'engage', 'excavations', 'formal', 'format', 'formerly', 'founder', 'fund', 'giants', 'gilbert', 'huge', 'hull', 'kansas', 'kevin', 'measured', 'mechanical', 'moore', 'moral', 'objective', 'oh', 'parish', 'philosophy', 'presentation', 'remarked', 'revolutionary', 'russia', 'scheme', 'scully', 'shop', 'sort', 'starred', 'sufficient', 'tactics', 'tanks', 'tide', 'trained', 'twin', 'understand', 'usage', 'variation', 'virgin', 'westward', 'wiśniowiecki', '130', '1926', '79', 'ambassador', 'arriving', 'audiences', 'benefit', 'blues', 'cavalry', 'claiming', 'clearly', 'closest', 'column', 'communication', 'crake', 'crops', 'decides', 'del', 'describe', 'designer', 'determine', 'differences', 'displayed', 'duty', 'factory', 'feathers', 'feeding', 'frequent', 'graphics', 'hamlet', 'hokies', 'impressed', 'inscription', 'intention', 'jobs', 'magnetic', 'mrs', 'nick', 'opponent', 'oscar', 'partner', 'persian', 'plus', 'predecessor', 'publications', 'ranging', 'regiments', 'residential', 'revival', 'schedule', 'skills', 'spiritual', 'strategy', 'streak', 'styles', 'texts', 'trek', 'valuable', 'vote', 'voyage', 'warren', '07', '1905', 'abby', 'adaptation', 'argues', 'armament', 'arrive', 'artwork', 'aside', 'aspect', 'attained', 'badly', 'batteries', 'blacks', 'brazil', 'cater', 'centers', 'chagas', 'commandment', 'conduct', 'considering', 'cruise', 'defending', 'definition', 'degrees', 'elections', 'ex', 'exclusively', 'garrison', 'grown', 'han', 'highways', 'isbn', 'jonathan', 'kelly', 'lay', 'leslie', 'machines', 'magnitude', 'malley', 'mathews', 'newspapers', 'pagan', 'peach', 'perspective', 'promised', 'prompted', 'protestant', 'quarterback', 'ranking', 'releases', 'restricted', 'roots', 'rough', 'ruling', 'temporary', 'turks', 'updated', 'valkyria', 'victorian', 'waiting', 'willing', 'yo', '63', 'allen', 'amounts', 'anthem', 'artistic', 'attend', 'bands', 'bertin', 'bir', 'bones', 'boom', 'boundary', 'brooks', 'celebrated', 'charged', 'chronicles', 'cinema', 'clark', 'code', 'comics', 'cotton', 'crews', 'dave', 'deemed', 'deity', 'disappeared', 'erected', 'exists', 'explains', 'fifty', 'furthermore', 'globe', 'handled', 'heroes', 'hudson', 'inhabitants', 'injured', 'investigation', 'jackets', 'las', 'liberal', 'magadheera', 'metre', 'nebraska', 'northeastern', 'northward', 'nurse', 'owners', 'refer', 'relation', 'repeated', 'resumed', 'retreat', 'roberts', 'spaces', 'strengthened', 'structural', 'suicide', 'talent', 'testing', 'tourist', 'uefa', '“', '160', '1890', '1924', '1925', '88', 'asomtavruli', 'assassination', 'banned', 'basement', 'breed', 'brick', 'chain', 'circle', 'constant', 'davis', 'demands', 'demonstrated', 'der', 'diamond', 'difference', 'distinctive', 'djokovic', 'dominant', 'emmy', 'enters', 'executed', 'exposed', 'harold', 'herzegovina', 'honour', 'inscriptions', 'landings', 'lies', 'madrid', 'meteorological', 'nielsen', 'organisation', 'peaking', 'prevented', 'profile', 'pryce', 'pure', 'pursue', 'referring', 'runners', 'scattered', 'seas', 'seek', 'settlements', 'soft', 'southeastern', 'stores', 'substitute', 'trophy', 'turrets', 'viet', 'ward', 'yankees', '05', '140', '1934', 'acre', 'acute', 'afternoon', 'alfred', 'altered', 'anglo', 'approval', 'assisted', 'bible', 'card', 'cargo', 'celtic', 'commandos', 'cong', 'congo', 'cool', 'corner', 'defend', 'defenders', 'discuss', 'edges', 'false', 'fee', 'feels', 'hostile', 'houston', 'indicating', 'initiated', 'jay', 'jews', 'labor', 'liked', 'loan', 'madison', 'magazines', 'mbar', 'melody', 'murray', 'philip', 'pictures', 'pounds', 'premiere', 'print', 'runway', 'sixteen', 'stood', 'striking', 'subjects', 'sunk', 'suspended', 'tennessee', 'thin', 'tournaments', 'translation', 'valve', 'warrior', 'weir', '08', '1000', '1908', '74', '93', 'architectural', 'barry', 'biological', 'cent', 'certainly', 'chevaliers', 'clock', 'colleagues', 'concern', 'conclusion', 'conservative', 'delivery', 'drug', 'du', 'eliminated', 'equal', 'ethnic', 'fair', 'federation', 'genetic', 'geoff', 'gift', 'goddess', 'guilty', 'harbour', 'hawaii', 'keeping', 'kurt', 'mariana', 'measurements', 'ndh', 'ontario', 'orchestra', 'ordering', 'outbreak', 'paramount', 'presidential', 'pretty', 'programming', 'reader', 'realized', 'rebuilt', 'receives', 'reducing', 'requested', 'respective', 'reveal', 'romanian', 'sas', 'seem', 'sheffield', 'signs', 'swiss', 'toured', 'underneath', 'violent', 'wagner', 'walking', 'weapon']\n","4099\n","(4099, 300)\n","4099 words of dimension 300 : <unk>, the, ,, ., ..., violent, wagner, walking, weapon\n","Computing neighbors\n","Mean: 13.238350817272506\n","Median: 6.0\n","she-he\n","her-his\n","sisters-colleagues\n","sister-brothers\n","husband-father\n","carey-coleman\n","artist-journalist\n","damaged-severe\n","decides-refused\n","child-group\n","fate-opposition\n","1952-1960\n","woman-letter\n","hair-bones\n","parents-opponents\n","island-lands\n","tried-led\n","performance-speech\n","elizabeth-charles\n","thought-knew\n","daughter-dublin\n","mother-wife\n","seen-dismissed\n","student-junior\n","escape-prevent\n","tennyson-alkan\n","rosebery-wheeler\n","covered-dominated\n","acting-manager\n","chief-general\n","charlie-kick\n","met-faced\n","album-perspective\n","image-popularity\n","beyoncé-lennon\n","moment-trial\n","mary-louis\n","credited-combined\n","injured-wounded\n","death-supporters\n","albums-titles\n","japan-1905\n","appointed-former\n","said-noted\n","jane-intention\n","gray-arthur\n","desire-score\n","sing-give\n","shoot-drop\n","episodes-games\n","1915-1944\n","contrast-furthermore\n","entry-league\n","arrival-territories\n","returns-return\n","crew-ustaše\n","choice-view\n","busch-wilhelm\n","vocals-r\n","2004-2006\n","assisted-succeeded\n","holy-roman\n","lord-harold\n","wall-window\n","wants-promised\n","restored-granted\n","phase-results\n","baby-job\n","search-actions\n","atlanta-yankees\n","ocean-eastern\n","zoo-conference\n","1917-1921\n","producer-jonathan\n","dave-matt\n","nominated-awarded\n","rebuilt-unsuccessful\n","enemy-garrison\n","raise-sell\n","ll-ve\n","going-say\n","collaboration-connection\n","relationship-conflict\n","arrangement-statement\n","1890-1934\n","soundtrack-novel\n","lives-settlement\n","peter-paul\n","gate-stadium\n","part-commander\n","waiting-reasons\n","interested-1927\n","girls-boys\n","marlborough-calvert\n","gwen-someone\n","decided-agreed\n","minutes-goals\n","rest-capture\n","cut-step\n","deities-authors\n","slowly-quickly\n","federal-grant\n","fey-nesbitt\n","paris-pennsylvania\n","meet-fly\n","kind-practice\n","macleod-bolívar\n","unable-promoted\n","1965-2000\n","depth-total\n","children-students\n","fuel-mechanical\n","ship-germans\n","stem-bulls\n","henry-stephen\n","goddess-successor\n","corner-point\n","nicole-tessa\n","care-responsibility\n","attempting-leads\n","actress-nomination\n","safe-sas\n","success-review\n","queen-king\n","1980s-1960s\n","cave-southwest\n","survived-lost\n","recording-industry\n","enter-defend\n","honour-bishop\n","crazy-k\n","him-himself\n","believes-suggests\n","1990-1962\n","britain-ireland\n","5-54\n","duty-serve\n","department-michigan\n","jones-lawrence\n","falls-kent\n","marriage-assassination\n","writer-scholar\n","appearance-pitcher\n","reveals-showed\n","1925-1978\n","presence-study\n","suggest-indicate\n","couple-chance\n","village-area\n","expected-required\n","sang-joined\n","go-move\n","hours-companies\n","sunk-attacked\n","song-jin\n","popular-prominent\n","appear-remain\n","cruiser-cavalry\n","fungus-archaeologist\n","melody-problem\n","altar-side\n","officer-senior\n","flow-lower\n","night-simpsons\n","relationships-relations\n","distinctive-theory\n","australians-generals\n","wanted-join\n","supposed-elected\n","buried-involved\n","transport-routes\n","placed-held\n","job-position\n","especially-italy\n","method-policy\n","constitution-government\n","wearing-holding\n","chorus-background\n","material-elements\n","write-gain\n","objective-orders\n","object-ordering\n","bono-kurt\n","protagonist-player\n","murder-edward\n","own-followers\n","advantage-loss\n","sir-lieutenant\n","voice-belief\n","worship-practices\n","wedding-friend\n","fall-grow\n","preparation-competition\n","fire-defenders\n","same-following\n","manga-book\n","remarked-concluded\n","intended-assigned\n","show-bbc\n","regarded-describes\n","maria-priest\n","causing-allowing\n","georgia-florida\n","designed-issued\n","oscar-michael\n","bay-fur\n","characters-figures\n","armor-belt\n","dam-helmet\n","rihanna-ign\n","accept-attend\n","color-skin\n","featuring-containing\n","written-responded\n","spain-torres\n","version-product\n","tournament-team\n","managed-advanced\n","engineer-infantry\n","videos-video\n","creation-establishment\n","home-chelsea\n","pool-victory\n","1987-1979\n","track-field\n","900-74\n","prince-anglo\n","heard-learned\n","christ-catholic\n","played-defeated\n","born-1948\n","versions-instruments\n","santa-la\n","really-pretty\n","city-county\n","cinema-2009\n","india-palestine\n","water-wind\n","feet-acres\n","labour-democratic\n","simone-dylan\n","70-36\n","pleasure-maryland\n","walk-pass\n","size-terms\n","hornung-finkelstein\n","seasons-teams\n","poor-financial\n","parvati-hand\n","kitsune-word\n","noting-suggesting\n","sold-bought\n","discovered-suggested\n","200-120\n","cases-survive\n","light-brigade\n","basic-useful\n","starlings-populations\n","warrior-pope\n","anything-nothing\n","composed-directed\n","tanks-bridges\n","music-classical\n","stay-0\n","battle-allied\n","compared-contributed\n","unknown-there\n","pop-b\n","composition-origin\n","primary-secondary\n","28-27\n","war-champion\n","art-arts\n","episode-hokies\n","released-collected\n","explained-explains\n","actor-assistant\n","model-technique\n","exchange-portugal\n","kelly-johnson\n","though-although\n","simpsons-cubs\n","straight-murray\n","da-barry\n","produced-brought\n","cannot-can\n","46-72\n","decade-season\n","extent-injury\n","liverpool-rangers\n","education-research\n","you-they\n","mentioned-informed\n","turrets-landings\n","believe-hoped\n","rain-damage\n","experiences-skills\n","shooting-clock\n","respect-reason\n","22-31\n","public-committee\n","torpedo-steam\n","america-korean\n","2011-2012\n","stopped-ball\n","bird-réunion\n","able-sent\n","variety-survey\n","mrs-d\n","mind-progress\n","peaking-wimbledon\n","05-07\n","2002-2008\n","estimated-reported\n","biggest-highest\n","coming-penalty\n","passes-runs\n","le-jean\n","leaves-crosses\n","particular-false\n","cathedral-churches\n","hms-german\n","rate-cost\n","finkelstein-mosley\n","five-32\n","arriving-mountains\n","residence-congress\n","crisis-decline\n","best-worst\n","heavy-coastal\n","destruction-majority\n","12-16\n","doubt-longer\n","genre-role\n","proposal-report\n","aml-injuries\n","port-northeast\n","co-davis\n","organization-political\n","150-160\n","reign-rule\n","capital-territory\n","historians-arab\n","empire-campaign\n","french-british\n","kill-carry\n","find-represent\n","walking-face\n","moon-panel\n","r-g\n","20th-bce\n","ends-becomes\n","feelings-religion\n","gone-fallen\n","right-throw\n","images-styles\n","25-14\n","series-phillies\n","floor-spot\n","1939-richmond\n","u-j\n","context-genus\n","professional-baseball\n","tied-goal\n","wrote-critic\n","ryan-samuel\n","europe-western\n","depicted-such\n","sort-means\n","production-creative\n","1932-matches\n","keats-biographer\n","1975-1947\n","16th-12th\n","2003-wrestling\n","olivier-mccall\n","unique-strongly\n","purchase-secure\n","twelve-eight\n","mix-variety\n","der-morrison\n","budget-fee\n","cast-guest\n","room-hospital\n","green-red\n","performed-featured\n","world-european\n","planning-plan\n","june-march\n","cup-uefa\n","additionally-jr\n","evita-juan\n","khandoba-ability\n","speed-minimum\n","charged-replaced\n","57-62\n","poetry-literary\n","will-must\n","always-wrong\n","atmosphere-discovery\n","uk-blacks\n","fifty-49\n","shakespeare-1924\n","lot-bit\n","finishing-scoring\n","television-program\n","1974-1971\n","life-politics\n","djedkare-odaenathus\n","quality-existence\n","temperature-effect\n","childhood-career\n","officially-formally\n","tail-approach\n","combination-crowd\n","townsend-stevens\n","begun-already\n","street-road\n","north-south\n","hear-bring\n","get-reveal\n","iguanodon-specimens\n","condoms-condom\n","eggs-subspecies\n","play-tie\n","summer-olympics\n","canyon-basin\n","me-see\n","taken-obtained\n","incorporated-split\n","sun-turks\n","argues-indicated\n","flooding-problems\n","revealed-announced\n","leslie-jack\n","l-v\n","gary-thomas\n","removed-eliminated\n","wiśniowiecki-weir\n","true-ninth\n","game-bowl\n","example-inspiration\n","arrive-promotion\n","sound-concept\n","1954-1964\n","football-premier\n","richard-taylor\n","began-started\n","completed-followed\n","texas-madison\n","storyline-dramatic\n","attack-offensive\n","argentina-france\n","eliminated-prevented\n","singing-playing\n","1941-1940\n","got-liked\n","september-november\n","asked-offered\n","better-rather\n","wilde-valuable\n","periods-period\n","sex-behavior\n","driven-saved\n","generation-year\n","soft-produce\n","impressed-mixed\n","health-mental\n","love-singing\n","length-spores\n","receive-allow\n","women-vote\n","films-magazines\n","foreign-regional\n","train-shop\n","attempt-defeat\n","fourth-third\n","poem-jain\n","parish-protestant\n","commanded-colonel\n","freeway-link\n","ace-attorney\n","support-assistance\n","squadron-regiment\n","1935-1991\n","process-revolutionary\n","fit-refer\n","incident-coup\n","country-region\n","convection-pressure\n","introduction-comics\n","signs-views\n","california-chicago\n","mediterranean-fleet\n","assumed-ruled\n","homes-soldiers\n","commented-drew\n","streak-winning\n","fresh-flank\n","gun-platoon\n"]}]},{"cell_type":"code","source":["# profession analysis gender\n","sp = sorted([(we.v(w).dot(v_gender), w) for w in profession_words])\n","\n","sp[:10], sp[-10:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4XWwlRlh0fZ1","executionInfo":{"status":"ok","timestamp":1669488498122,"user_tz":300,"elapsed":314,"user":{"displayName":"Siqi Hao","userId":"16003167311170492372"}},"outputId":"0951e2bf-151e-4d29-90ae-737fe85f84b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([(-0.20932901, 'scholar'),\n","  (-0.20775622, 'manager'),\n","  (-0.20657085, 'historian'),\n","  (-0.20091595, 'archaeologist'),\n","  (-0.1796024, 'colonel'),\n","  (-0.1648269, 'professor'),\n","  (-0.16066456, 'baker'),\n","  (-0.13986644, 'journalist'),\n","  (-0.12611066, 'attorney'),\n","  (-0.12416956, 'lieutenant')],\n"," [(0.07598993, 'ambassador'),\n","  (0.07828899, 'student'),\n","  (0.112663895, 'warrior'),\n","  (0.11741469, 'musician'),\n","  (0.13862993, 'singer'),\n","  (0.15350245, 'protagonist'),\n","  (0.15932953, 'character'),\n","  (0.1836084, 'actor'),\n","  (0.23542948, 'actress'),\n","  (0.28367192, 'artist')])"]},"metadata":{},"execution_count":11}]}]}